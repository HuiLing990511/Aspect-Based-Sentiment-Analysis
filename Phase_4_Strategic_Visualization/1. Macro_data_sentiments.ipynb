{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53d05a41",
   "metadata": {},
   "source": [
    "# Batch Inference: Sentiment Predictions for Power BI Dashboard\n",
    "\n",
    "**Purpose**: Apply trained XLM-RoBERTa model to the ENTIRE dataset (all aspect-segment pairs) to generate sentiment predictions for Power BI visualization and Kano Model analysis.\n",
    "\n",
    "**Input**: \n",
    "- Trained Model: `Modelling/models/xlm_roberta_absa_best.pt`\n",
    "- Full Dataset: `Dataset/aspect_categorization_refined.pkl` (with XLM-RoBERTa aspect categorization)\n",
    "\n",
    "**Output**:\n",
    "- `Dataset/segment_level_predictions.csv` - Segment-level predictions with confidence scores\n",
    "- `Dataset/restaurant_aspect_aggregates.csv` - Aggregated by restaurant + aspect (for Power BI)\n",
    "- `Dataset/kano_model_input.csv` - Formatted for Kano Model categorization\n",
    "\n",
    "---\n",
    "\n",
    "## Academic Justification\n",
    "\n",
    "This inference pipeline transforms weak supervision training outputs into actionable business intelligence:\n",
    "\n",
    "1. **Full Dataset Coverage**: Unlike train/test splits, we predict on ALL segments to maximize coverage for stakeholder insights\n",
    "2. **Confidence Scoring**: Softmax probabilities allow filtering uncertain predictions (threshold: p > 0.6)\n",
    "3. **Aspect-Level Aggregation**: Following Pontiki et al. (2016), we aggregate segment sentiments to aspect-level for restaurant profiling\n",
    "4. **Kano Model Integration**: Sentiment distributions per aspect feed into Kano categorization (Must-Have vs Attractive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1158cd",
   "metadata": {},
   "source": [
    "# STAGE 0: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7640ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to google drive\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# 1. Mount Google Drive (To save the model checkpoints)\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 2. Install Libraries \n",
    "!pip install transformers accelerate tokenizers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac9b6db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ENVIRONMENT CHECK\n",
      "======================================================================\n",
      "  Python:      3.10.11\n",
      "  PyTorch:     2.8.0+cpu\n",
      "  CUDA Avail:  False\n",
      "======================================================================\n",
      "\n",
      "âœ“ Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Import Required Libraries\n",
    "# ==============================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# PyTorch & Transformers\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "# Progress tracking\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Visualization (for quick sanity checks)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ENVIRONMENT CHECK\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"  Python:      {sys.version.split()[0]}\")\n",
    "print(f\"  PyTorch:     {torch.__version__}\")\n",
    "print(f\"  CUDA Avail:  {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  GPU Device:  {torch.cuda.get_device_name(0)}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Set device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nâœ“ Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf62662c",
   "metadata": {},
   "source": [
    "# STAGE 1: Configuration & Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c176038a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CONFIGURATION\n",
      "======================================================================\n",
      "  Model Path:      C:\\Users\\Ong Hui Ling\\Dropbox\\PC\\Documents\\Github\\Aspect-Based-Sentiment-Analysis\\Modelling\\models\\xlm_roberta_absa_best.pt\n",
      "    Exists:        True\n",
      "\n",
      "  Data Path:       C:\\Users\\Ong Hui Ling\\Dropbox\\PC\\Documents\\Github\\Aspect-Based-Sentiment-Analysis\\Dataset\\aspect_categorization_refined.pkl\n",
      "    Exists:        True\n",
      "\n",
      "  Output Directory: C:\\Users\\Ong Hui Ling\\Dropbox\\PC\\Documents\\Github\\Aspect-Based-Sentiment-Analysis\\Dataset\n",
      "    Exists:        True\n",
      "\n",
      "  Batch Size:      64\n",
      "  Confidence Threshold: 0.7\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Configuration for Batch Inference\n",
    "# ==============================================================================\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class InferenceConfig:\n",
    "    \"\"\"Configuration for applying trained model to full dataset.\n",
    "    \n",
    "    Why separate from training config:\n",
    "        Inference has different requirements - no train/val split, larger\n",
    "        batch sizes (no backprop = more GPU memory), and different output paths.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- Model & Tokenizer ------------------------------------------------\n",
    "    model_name: str = \"xlm-roberta-base\"\n",
    "    #model_path: str = r\"C:\\Users\\Ong Hui Ling\\Dropbox\\PC\\Documents\\Github\\Aspect-Based-Sentiment-Analysis\\Modelling\\models\\xlm_roberta_absa_best.pt\"\n",
    "    \n",
    "    model_path: str = r\"\\content\\drive\\MyDrive\\Aspect-Based-Sentiment-Analysis\\Modelling\\models\\xlm_roberta_absa_best_after_filtering.pt\"\n",
    "    num_labels: int = 2  # 0=negative, 1=positive\n",
    "    \n",
    "    # --- Input Data -------------------------------------------------------\n",
    "    # Use the FULL dataset with XLM-RoBERTa aspect categorization applied\n",
    "    # (Same as training data to ensure consistency)\n",
    "    #data_path: str = r\"C:\\Users\\Ong Hui Ling\\Dropbox\\PC\\Documents\\Github\\Aspect-Based-Sentiment-Analysis\\Dataset\\aspect_categorization_refined.pkl\"\n",
    "    data_path: str = r\"\\content\\drive\\MyDrive\\Aspect-Based-Sentiment-Analysis\\Dataset\\aspect_categorization_refined.pkl\"\n",
    "    \n",
    "    # --- Inference Parameters ---------------------------------------------\n",
    "    batch_size: int = 64  # Larger than training (no gradients = more memory)\n",
    "    max_seq_length: int = 128\n",
    "    \n",
    "    # Confidence threshold: flag predictions with p < threshold for review\n",
    "    confidence_threshold: float = 0.7\n",
    "    # Academic Rationale (Hendrycks & Gimpel, 2017 - \"A Baseline for Detecting \n",
    "    # Misclassified and Out-of-Distribution Examples in Neural Networks\"):\n",
    "    #   - Standard practice: 0.5 (decision boundary) to 0.9 (high precision)\n",
    "    #   - Weak supervision context: Higher threshold (0.7-0.8) recommended\n",
    "    #   - Trade-off: Lower threshold â†’ more coverage, higher noise\n",
    "    #                Higher threshold â†’ less coverage, higher precision\n",
    "    # \n",
    "    # Empirical Guideline (see confidence analysis below):\n",
    "    #   0.5-0.6: Accept all predictions (high recall, lower precision)\n",
    "    #   0.7-0.8: Balanced - flag ~20-30% for review (recommended for BI)\n",
    "    #   0.9+:    High precision - flag ~50%+ for review (too conservative)\n",
    "    \n",
    "    # --- Output Files (for Power BI consumption) --------------------------\n",
    "    #output_dir: str = r\"C:\\Users\\Ong Hui Ling\\Dropbox\\PC\\Documents\\Github\\Aspect-Based-Sentiment-Analysis\\Dataset\"\n",
    "    output_dir: str = r\"\\content\\drive\\MyDrive\\Aspect-Based-Sentiment-Analysis\\Dataset\"\n",
    "    \n",
    "    # Segment-level predictions (one row per aspect-segment pair)\n",
    "    segment_predictions_path: str = os.path.join(output_dir, \"segment_level_predictions.csv\")\n",
    "    \n",
    "    # Restaurant-Aspect aggregates (grouped by restaurant + aspect)\n",
    "    restaurant_aggregates_path: str = os.path.join(output_dir, \"restaurant_aspect_aggregates.csv\")\n",
    "    \n",
    "    # Kano Model input (sentiment distribution per aspect category)\n",
    "    kano_input_path: str = os.path.join(output_dir, \"kano_model_input.csv\")\n",
    "    \n",
    "    # Summary statistics (for quick validation)\n",
    "    summary_path: str = os.path.join(output_dir, \"prediction_summary.json\")\n",
    "\n",
    "\n",
    "CFG = InferenceConfig()\n",
    "\n",
    "# Validate paths\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CONFIGURATION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"  Model Path:      {CFG.model_path}\")\n",
    "print(f\"    Exists:        {os.path.exists(CFG.model_path)}\")\n",
    "print(f\"\\n  Data Path:       {CFG.data_path}\")\n",
    "print(f\"    Exists:        {os.path.exists(CFG.data_path)}\")\n",
    "print(f\"\\n  Output Directory: {CFG.output_dir}\")\n",
    "print(f\"    Exists:        {os.path.exists(CFG.output_dir)}\")\n",
    "print(f\"\\n  Batch Size:      {CFG.batch_size}\")\n",
    "print(f\"  Confidence Threshold: {CFG.confidence_threshold}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Label encoding (must match training)\n",
    "LABEL2ID = {\"negative\": 0, \"positive\": 1}\n",
    "ID2LABEL = {0: \"negative\", 1: \"positive\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02efbf92",
   "metadata": {},
   "source": [
    "## ðŸ“Š Confidence Threshold Selection\n",
    "\n",
    "**Academic Context:**\n",
    "- **Hendrycks & Gimpel (2017)** - \"A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks\" established that softmax confidence correlates with prediction correctness\n",
    "- **Guo et al. (2017)** - \"On Calibration of Modern Neural Networks\" showed that while deep networks are often overconfident, thresholds of 0.7-0.8 provide good precision-recall balance\n",
    "- **Ratner et al. (2016)** - \"Data Programming\" (weak supervision framework) recommends higher thresholds (â‰¥0.7) when labels are noisy\n",
    "\n",
    "**Practical Guidelines:**\n",
    "- **Business Intelligence Context**: You want high-confidence predictions for strategic decisions\n",
    "- **Weak Supervision**: Your training labels (star ratings) are noisy â†’ conservative threshold needed\n",
    "- **Power BI Use Case**: Flagging low-confidence predictions allows stakeholders to focus on reliable insights\n",
    "\n",
    "**Recommended Range**: 0.7 - 0.8 (we'll validate empirically after inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7e8eec",
   "metadata": {},
   "source": [
    "# STAGE 2: Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8021cbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LOADING MODEL & TOKENIZER\n",
      "======================================================================\n",
      "  âœ“ Tokenizer loaded: xlm-roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âš ï¸  Detected custom training wrapper. Extracting backbone weights...\n",
      "  âœ“ Successfully loaded 201 backbone parameters\n",
      "  âœ“ Model loaded from: C:\\Users\\Ong Hui Ling\\Dropbox\\PC\\Documents\\Github\\Aspect-Based-Sentiment-Analysis\\Modelling\\models\\xlm_roberta_absa_best.pt\n",
      "  âœ“ Model moved to: cpu\n",
      "  âœ“ Evaluation mode: ON (dropout disabled)\n",
      "  âœ“ Total parameters: 278,045,186\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Load Pre-Trained Model & Tokenizer\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"LOADING MODEL & TOKENIZER\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load tokenizer (same as training)\n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.model_name)\n",
    "print(f\"  âœ“ Tokenizer loaded: {CFG.model_name}\")\n",
    "\n",
    "# Load model architecture (must match training setup)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    CFG.model_name,\n",
    "    num_labels=CFG.num_labels,\n",
    ")\n",
    "\n",
    "# Load trained weights from checkpoint\n",
    "# map_location ensures compatibility if trained on GPU but inferring on CPU\n",
    "checkpoint = torch.load(CFG.model_path, map_location=DEVICE)\n",
    "\n",
    "# Handle custom wrapper: Training used ABSASentimentClassifier with 'backbone' prefix\n",
    "# Extract only the backbone weights (remove 'backbone.' prefix)\n",
    "if any(key.startswith('backbone.') for key in checkpoint.keys()):\n",
    "    print(f\"  âš ï¸  Detected custom training wrapper. Extracting backbone weights...\")\n",
    "    state_dict = {\n",
    "        key.replace('backbone.', ''): value \n",
    "        for key, value in checkpoint.items() \n",
    "        if key.startswith('backbone.')\n",
    "    }\n",
    "    model.load_state_dict(state_dict)\n",
    "    print(f\"  âœ“ Successfully loaded {len(state_dict)} backbone parameters\")\n",
    "else:\n",
    "    # Direct loading (if checkpoint structure matches)\n",
    "    model.load_state_dict(checkpoint)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "model.eval()  # Set to evaluation mode (disables dropout)\n",
    "\n",
    "print(f\"  âœ“ Model loaded from: {CFG.model_path}\")\n",
    "print(f\"  âœ“ Model moved to: {DEVICE}\")\n",
    "print(f\"  âœ“ Evaluation mode: ON (dropout disabled)\")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"  âœ“ Total parameters: {total_params:,}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5249be84",
   "metadata": {},
   "source": [
    "# STAGE 3: Load Full Dataset (No Train/Val/Test Split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3733660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LOADING FULL DATASET\n",
      "======================================================================\n",
      "  âœ“ Dataset loaded: 129,034 rows\n",
      "\n",
      "  Data Quality Checks:\n",
      "    Missing segments:   0\n",
      "    Missing aspects:    0\n",
      "    Empty segments:     0\n",
      "\n",
      "  Available Columns:\n",
      "    - Original_Review_ID\n",
      "    - Full_Review\n",
      "    - Segment\n",
      "    - Sentiment_Label\n",
      "    - Aspect_Labels\n",
      "    - Aspect_Labels_dict\n",
      "\n",
      "  Aspect Label Distribution:\n",
      "    Single-aspect segments:  99,900 (77.4%)\n",
      "    Multi-aspect segments:   29,134 (22.6%)\n",
      "\n",
      "  âœ“ Processing ALL segments (single + multi-aspect)\n",
      "    Total segments to predict: 129,034\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Load FULL Dataset for Inference\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"LOADING FULL DATASET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "df_full = pd.read_pickle(CFG.data_path)\n",
    "print(f\"  âœ“ Dataset loaded: {len(df_full):,} rows\")\n",
    "\n",
    "# Data quality checks\n",
    "print(f\"\\n  Data Quality Checks:\")\n",
    "print(f\"    Missing segments:   {df_full['Segment'].isna().sum()}\")\n",
    "print(f\"    Missing aspects:    {df_full['Aspect_Labels'].isna().sum()}\")\n",
    "print(f\"    Empty segments:     {(df_full['Segment'].str.strip() == '').sum()}\")\n",
    "\n",
    "# Show column overview\n",
    "print(f\"\\n  Available Columns:\")\n",
    "for col in df_full.columns:\n",
    "    print(f\"    - {col}\")\n",
    "\n",
    "# Show aspect distribution\n",
    "print(f\"\\n  Aspect Label Distribution:\")\n",
    "# Count single vs multi-aspect segments\n",
    "df_full['num_aspects'] = df_full['Aspect_Labels'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "single_aspect = (df_full['num_aspects'] == 1).sum()\n",
    "multi_aspect = (df_full['num_aspects'] > 1).sum()\n",
    "print(f\"    Single-aspect segments:  {single_aspect:,} ({single_aspect/len(df_full)*100:.1f}%)\")\n",
    "print(f\"    Multi-aspect segments:   {multi_aspect:,} ({multi_aspect/len(df_full)*100:.1f}%)\")\n",
    "\n",
    "# We'll process ALL segments (including multi-aspect)\n",
    "print(f\"\\n  âœ“ Processing ALL segments (single + multi-aspect)\")\n",
    "print(f\"    Total segments to predict: {len(df_full):,}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b678155c",
   "metadata": {},
   "source": [
    "# STAGE 4: Prepare Data for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dc9189e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PREPARING DATA FOR ASPECT-CONDITIONAL INFERENCE\n",
      "======================================================================\n",
      "  Original rows:           129,034\n",
      "  After exploding:         163,667 (segment, aspect) pairs\n",
      "  Increase factor:         1.27x\n",
      "\n",
      "  Aspect Distribution (after exploding):\n",
      "    FOOD                          : 72,064 pairs ( 44.0%)\n",
      "    SERVICE                       : 24,352 pairs ( 14.9%)\n",
      "    AMBIENCE                      : 20,177 pairs ( 12.3%)\n",
      "    LOYALTY (RETURN INTENT)       : 18,176 pairs ( 11.1%)\n",
      "    VALUE                         : 14,212 pairs (  8.7%)\n",
      "    LOCATION                      :  6,408 pairs (  3.9%)\n",
      "    AUTHENTICITY & LOCAL VIBE     :  5,061 pairs (  3.1%)\n",
      "    NON-HALAL ELEMENTS            :  2,422 pairs (  1.5%)\n",
      "    HALAL COMPLIANCE              :    792 pairs (  0.5%)\n",
      "    GENERAL                       :      3 pairs (  0.0%)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Explode Multi-Aspect Segments for Aspect-Conditional Prediction\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PREPARING DATA FOR ASPECT-CONDITIONAL INFERENCE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Each segment can have multiple aspects. We need to predict sentiment for\n",
    "# EACH (segment, aspect) pair separately because the same segment can have\n",
    "# different sentiments for different aspects.\n",
    "#\n",
    "# Example:\n",
    "#   Segment: \"The food was amazing but service was slow\"\n",
    "#   Aspects: [FOOD, SERVICE]\n",
    "#   â†’ We need 2 predictions:\n",
    "#       (segment, FOOD)    â†’ likely POSITIVE\n",
    "#       (segment, SERVICE) â†’ likely NEGATIVE\n",
    "\n",
    "# Explode: Create one row per (segment, aspect) pair\n",
    "df_exploded = df_full.explode('Aspect_Labels').reset_index(drop=True)\n",
    "df_exploded.rename(columns={'Aspect_Labels': 'aspect'}, inplace=True)\n",
    "\n",
    "print(f\"  Original rows:           {len(df_full):,}\")\n",
    "print(f\"  After exploding:         {len(df_exploded):,} (segment, aspect) pairs\")\n",
    "print(f\"  Increase factor:         {len(df_exploded)/len(df_full):.2f}x\")\n",
    "\n",
    "# Show aspect distribution after exploding\n",
    "print(f\"\\n  Aspect Distribution (after exploding):\")\n",
    "aspect_counts = df_exploded['aspect'].value_counts()\n",
    "for aspect, count in aspect_counts.items():\n",
    "    print(f\"    {aspect:<30}: {count:>6,} pairs ({count/len(df_exploded)*100:>5.1f}%)\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1578fc",
   "metadata": {},
   "source": [
    "# STAGE 5: Create PyTorch Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7639843a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BUILDING DATALOADER\n",
      "======================================================================\n",
      "  âœ“ Dataset size:      163,667 (segment, aspect) pairs\n",
      "  âœ“ Batch size:        64\n",
      "  âœ“ Number of batches: 2,558\n",
      "  âœ“ Shuffle:           OFF (preserves row order)\n",
      "\n",
      "  Sample Input (decoded):\n",
      "    \"<s> AMBIENCE</s></s> a must-visit for true malaysian comfort food</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\"\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# PyTorch Dataset for Inference (No Labels Needed)\n",
    "# ==============================================================================\n",
    "\n",
    "class InferenceDataset(Dataset):\n",
    "    \"\"\"Aspect-conditioned dataset for inference (no labels).\n",
    "    \n",
    "    Same input format as training: \"[ASPECT] </s></s> [segment text]\"\n",
    "    But we don't need labels since we're only predicting, not training.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df: pd.DataFrame, tokenizer, max_length: int = 128):\n",
    "        self.texts = df['Segment'].tolist()\n",
    "        self.aspects = df['aspect'].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        aspect = self.aspects[idx]\n",
    "        segment = self.texts[idx]\n",
    "        \n",
    "        # Aspect-conditioned input (same as training)\n",
    "        conditioned_text = f\"{aspect.upper()} </s></s> {segment}\"\n",
    "        \n",
    "        # Tokenize\n",
    "        encoding = self.tokenizer(\n",
    "            conditioned_text,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding=False,  # Dynamic padding in collator\n",
    "            return_tensors=None,\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'],\n",
    "            'attention_mask': encoding['attention_mask'],\n",
    "        }\n",
    "\n",
    "\n",
    "# Create dataset and dataloader\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"BUILDING DATALOADER\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "inference_dataset = InferenceDataset(df_exploded, tokenizer, CFG.max_seq_length)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "inference_loader = DataLoader(\n",
    "    inference_dataset,\n",
    "    batch_size=CFG.batch_size,\n",
    "    shuffle=False,  # IMPORTANT: Keep order to match predictions back to df_exploded\n",
    "    collate_fn=data_collator,\n",
    "    num_workers=0,  # Set to 0 for Windows compatibility\n",
    "    pin_memory=True if torch.cuda.is_available() else False,\n",
    ")\n",
    "\n",
    "n_batches = len(inference_loader)\n",
    "print(f\"  âœ“ Dataset size:      {len(inference_dataset):,} (segment, aspect) pairs\")\n",
    "print(f\"  âœ“ Batch size:        {CFG.batch_size}\")\n",
    "print(f\"  âœ“ Number of batches: {n_batches:,}\")\n",
    "print(f\"  âœ“ Shuffle:           OFF (preserves row order)\")\n",
    "\n",
    "# Quick sanity check: decode first sample\n",
    "sample_batch = next(iter(inference_loader))\n",
    "sample_text = tokenizer.decode(sample_batch['input_ids'][0], skip_special_tokens=False)\n",
    "print(f\"\\n  Sample Input (decoded):\")\n",
    "print(f\"    \\\"{sample_text}\\\"\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80037be5",
   "metadata": {},
   "source": [
    "# STAGE 6: Batch Inference (Generate Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17f3a87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RUNNING BATCH INFERENCE\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ac19aaba234febb78eae5ae4eee901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Predicting:   0%|          | 0/2558 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits  \u001b[38;5;66;03m# (batch_size, num_classes)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Convert logits to probabilities using softmax\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:1205\u001b[0m, in \u001b[0;36mXLMRobertaForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1197\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1199\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1200\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1202\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1203\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1205\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1211\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1212\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1215\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1216\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1217\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:834\u001b[0m, in \u001b[0;36mXLMRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    825\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    827\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m    828\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m    829\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    832\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m    833\u001b[0m )\n\u001b[1;32m--> 834\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    846\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    847\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:522\u001b[0m, in \u001b[0;36mXLMRobertaEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    511\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    512\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    513\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         output_attentions,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 522\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    532\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:411\u001b[0m, in \u001b[0;36mXLMRobertaLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    401\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    408\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 411\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    418\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:338\u001b[0m, in \u001b[0;36mXLMRobertaAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    330\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    336\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    337\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 338\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    348\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:188\u001b[0m, in \u001b[0;36mXLMRobertaSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    180\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    187\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 188\u001b[0m     mixed_query_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;66;03m# If this is instantiated as a cross-attention module, the keys\u001b[39;00m\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;66;03m# and values come from an encoder; the attention mask needs to be\u001b[39;00m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;66;03m# such that the encoder's padding tokens are not attended to.\u001b[39;00m\n\u001b[0;32m    193\u001b[0m     is_cross_attention \u001b[38;5;241m=\u001b[39m encoder_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Run Inference on ALL (Segment, Aspect) Pairs\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RUNNING BATCH INFERENCE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "all_predictions = []\n",
    "all_probabilities = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(tqdm(inference_loader, desc=\"  Predicting\")):\n",
    "        # Move batch to device\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # (batch_size, num_classes)\n",
    "        \n",
    "        # Convert logits to probabilities using softmax\n",
    "        probs = torch.softmax(logits, dim=-1)  # (batch_size, num_classes)\n",
    "        \n",
    "        # Get predicted class (argmax)\n",
    "        preds = torch.argmax(probs, dim=-1)  # (batch_size,)\n",
    "        \n",
    "        # Store results\n",
    "        all_predictions.extend(preds.cpu().numpy().tolist())\n",
    "        all_probabilities.extend(probs.cpu().numpy().tolist())\n",
    "\n",
    "print(f\"\\n  âœ“ Inference complete!\")\n",
    "print(f\"    Total predictions:  {len(all_predictions):,}\")\n",
    "print(f\"    Shape matches data: {len(all_predictions) == len(df_exploded)}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab443a1",
   "metadata": {},
   "source": [
    "# STAGE 7: Add Predictions to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794c15a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Add Predictions & Confidence Scores to DataFrame\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ADDING PREDICTIONS TO DATAFRAME\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Add raw predictions (0 or 1)\n",
    "df_exploded['predicted_sentiment_id'] = all_predictions\n",
    "\n",
    "# Add sentiment labels (negative/positive)\n",
    "df_exploded['predicted_sentiment'] = df_exploded['predicted_sentiment_id'].map(ID2LABEL)\n",
    "\n",
    "# Add probabilities for both classes\n",
    "# all_probabilities is a list of [prob_negative, prob_positive] for each sample\n",
    "probs_array = np.array(all_probabilities)\n",
    "df_exploded['prob_negative'] = probs_array[:, 0]\n",
    "df_exploded['prob_positive'] = probs_array[:, 1]\n",
    "\n",
    "# Add confidence score (probability of predicted class)\n",
    "# If predicted negative (0), confidence = prob_negative\n",
    "# If predicted positive (1), confidence = prob_positive\n",
    "df_exploded['confidence'] = [\n",
    "    probs_array[i, pred] for i, pred in enumerate(all_predictions)\n",
    "]\n",
    "\n",
    "# Flag low-confidence predictions for review\n",
    "df_exploded['is_high_confidence'] = df_exploded['confidence'] >= CFG.confidence_threshold\n",
    "\n",
    "# Show prediction statistics\n",
    "print(f\"\\n  Prediction Distribution:\")\n",
    "pred_counts = df_exploded['predicted_sentiment'].value_counts()\n",
    "for sentiment, count in pred_counts.items():\n",
    "    pct = count / len(df_exploded) * 100\n",
    "    print(f\"    {sentiment.capitalize():<10}: {count:>7,} ({pct:>5.1f}%)\")\n",
    "\n",
    "print(f\"\\n  Confidence Statistics:\")\n",
    "print(f\"    Mean confidence:       {df_exploded['confidence'].mean():.3f}\")\n",
    "print(f\"    Median confidence:     {df_exploded['confidence'].median():.3f}\")\n",
    "print(f\"    High confidence (>{CFG.confidence_threshold}): {df_exploded['is_high_confidence'].sum():,} ({df_exploded['is_high_confidence'].mean()*100:.1f}%)\")\n",
    "print(f\"    Low confidence (<={CFG.confidence_threshold}): {(~df_exploded['is_high_confidence']).sum():,} ({(~df_exploded['is_high_confidence']).mean()*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n  Per-Aspect Prediction Distribution:\")\n",
    "aspect_sentiment = df_exploded.groupby(['aspect', 'predicted_sentiment']).size().unstack(fill_value=0)\n",
    "print(aspect_sentiment)\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d981294",
   "metadata": {},
   "source": [
    "## STAGE 7b: Empirical Confidence Threshold Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dcf93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Empirical Analysis: Confidence Threshold Trade-offs\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CONFIDENCE THRESHOLD ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nðŸ“š Academic References:\")\n",
    "print(\"  [1] Hendrycks & Gimpel (2017) - 'A Baseline for Detecting Misclassified\")\n",
    "print(\"      and Out-of-Distribution Examples in Neural Networks'\")\n",
    "print(\"      â†’ Established softmax confidence as predictor of correctness\")\n",
    "print(\"\")\n",
    "print(\"  [2] Guo et al. (2017) - 'On Calibration of Modern Neural Networks'\")\n",
    "print(\"      â†’ Showed threshold 0.7-0.8 balances precision and recall\")\n",
    "print(\"\")\n",
    "print(\"  [3] Ratner et al. (2016) - 'Data Programming: Creating Large Training\")\n",
    "print(\"      Sets, Quickly' â†’ Weak supervision requires conservative thresholds\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Define threshold candidates\n",
    "thresholds = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "print(f\"\\n{'Threshold':<12} {'High Conf %':<15} {'Flagged %':<15} {'Mean Conf':<15} {'Interpretation'}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "threshold_analysis = []\n",
    "\n",
    "for thresh in thresholds:\n",
    "    high_conf_mask = df_exploded['confidence'] >= thresh\n",
    "    pct_high = (high_conf_mask.sum() / len(df_exploded)) * 100\n",
    "    pct_flagged = 100 - pct_high\n",
    "    mean_conf = df_exploded[high_conf_mask]['confidence'].mean() if high_conf_mask.sum() > 0 else 0\n",
    "    \n",
    "    # Interpretation based on literature\n",
    "    if thresh <= 0.6:\n",
    "        interpret = \"Liberal (High Recall)\"\n",
    "    elif thresh <= 0.75:\n",
    "        interpret = \"Balanced (Recommended)\"\n",
    "    elif thresh <= 0.85:\n",
    "        interpret = \"Conservative\"\n",
    "    else:\n",
    "        interpret = \"Very Conservative\"\n",
    "    \n",
    "    threshold_analysis.append({\n",
    "        'threshold': thresh,\n",
    "        'pct_high_conf': round(pct_high, 2),\n",
    "        'pct_flagged': round(pct_flagged, 2),\n",
    "        'mean_conf': round(mean_conf, 4),\n",
    "        'interpretation': interpret\n",
    "    })\n",
    "    \n",
    "    print(f\"{thresh:<12.1f} {pct_high:<15.1f} {pct_flagged:<15.1f} {mean_conf:<15.4f} {interpret}\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Confidence distribution percentiles\n",
    "print(f\"\\n  Confidence Score Percentiles:\")\n",
    "percentiles = [10, 25, 50, 75, 90, 95, 99]\n",
    "for p in percentiles:\n",
    "    val = np.percentile(df_exploded['confidence'], p)\n",
    "    print(f\"    {p:>2}th percentile: {val:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RECOMMENDATION (Based on Literature & Weak Supervision Context):\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"  Current Threshold: {CFG.confidence_threshold}\")\n",
    "print(f\"  High Confidence:   {(df_exploded['confidence'] >= CFG.confidence_threshold).sum():,} predictions ({(df_exploded['confidence'] >= CFG.confidence_threshold).mean()*100:.1f}%)\")\n",
    "print(f\"  Flagged for Review: {(df_exploded['confidence'] < CFG.confidence_threshold).sum():,} predictions ({(df_exploded['confidence'] < CFG.confidence_threshold).mean()*100:.1f}%)\")\n",
    "print(f\"\\n  âœ“ For Power BI Dashboard: 0.7-0.8 provides good balance\")\n",
    "print(f\"  âœ“ For High-Stakes Decisions: Use â‰¥0.8 and manually review flagged cases\")\n",
    "print(f\"  âœ“ For Maximum Coverage: Use â‰¥0.6 but note increased noise risk\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create confidence distribution visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left plot: Confidence histogram with threshold line\n",
    "ax1 = axes[0]\n",
    "ax1.hist(df_exploded['confidence'], bins=50, color='#3498db', edgecolor='black', alpha=0.7)\n",
    "ax1.axvline(CFG.confidence_threshold, color='red', linestyle='--', linewidth=2, \n",
    "            label=f'Current Threshold ({CFG.confidence_threshold})')\n",
    "ax1.axvline(0.8, color='orange', linestyle=':', linewidth=2, label='Conservative (0.8)')\n",
    "ax1.set_title('Confidence Score Distribution', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Confidence Score')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Right plot: Coverage vs Threshold trade-off\n",
    "ax2 = axes[1]\n",
    "thresh_range = np.linspace(0.5, 0.95, 50)\n",
    "coverage = [(df_exploded['confidence'] >= t).mean() * 100 for t in thresh_range]\n",
    "ax2.plot(thresh_range, coverage, linewidth=2, color='#2ecc71')\n",
    "ax2.axvline(CFG.confidence_threshold, color='red', linestyle='--', linewidth=2, \n",
    "            label=f'Current ({CFG.confidence_threshold})')\n",
    "ax2.axhline(80, color='gray', linestyle=':', alpha=0.5, label='80% Coverage')\n",
    "ax2.set_title('Coverage vs Confidence Threshold', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('Confidence Threshold')\n",
    "ax2.set_ylabel('Coverage (%)')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "ax2.set_ylim([0, 105])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(CFG.output_dir, 'confidence_threshold_analysis.png'), \n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nâœ“ Analysis saved to: {os.path.join(CFG.output_dir, 'confidence_threshold_analysis.png')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d52f38",
   "metadata": {},
   "source": [
    "# STAGE 8: Export Segment-Level Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e8730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Export Segment-Level Predictions (Full Detail)\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXPORTING SEGMENT-LEVEL PREDICTIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Select relevant columns for Power BI\n",
    "segment_export_cols = [\n",
    "    'Original_Review_ID',\n",
    "    'Restaurant_Name',\n",
    "    'Segment',\n",
    "    'aspect',\n",
    "    'predicted_sentiment',\n",
    "    'predicted_sentiment_id',\n",
    "    'confidence',\n",
    "    'prob_negative',\n",
    "    'prob_positive',\n",
    "    'is_high_confidence',\n",
    "]\n",
    "\n",
    "# Add weak label (star rating) if available for comparison\n",
    "if 'Sentiment_Label' in df_exploded.columns:\n",
    "    segment_export_cols.append('Sentiment_Label')\n",
    "\n",
    "df_segment_export = df_exploded[segment_export_cols].copy()\n",
    "\n",
    "# Save to CSV\n",
    "df_segment_export.to_csv(CFG.segment_predictions_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"  âœ“ Segment-level predictions saved\")\n",
    "print(f\"    Path:     {CFG.segment_predictions_path}\")\n",
    "print(f\"    Rows:     {len(df_segment_export):,}\")\n",
    "print(f\"    Columns:  {len(df_segment_export.columns)}\")\n",
    "print(f\"    File size: {os.path.getsize(CFG.segment_predictions_path) / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# Show sample\n",
    "print(f\"\\n  Sample rows:\")\n",
    "print(df_segment_export.head(3).to_string(index=False))\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dc6a3a",
   "metadata": {},
   "source": [
    "# STAGE 9: Aggregate by Restaurant + Aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536bd2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Aggregate Predictions by Restaurant + Aspect (for Power BI Dashboard)\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"AGGREGATING BY RESTAURANT + ASPECT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Group by restaurant and aspect\n",
    "agg_df = df_exploded.groupby(['Restaurant_Name', 'aspect']).agg(\n",
    "    total_segments=('Segment', 'count'),\n",
    "    num_positive=('predicted_sentiment_id', lambda x: (x == 1).sum()),\n",
    "    num_negative=('predicted_sentiment_id', lambda x: (x == 0).sum()),\n",
    "    avg_confidence=('confidence', 'mean'),\n",
    "    high_confidence_count=('is_high_confidence', 'sum'),\n",
    ").reset_index()\n",
    "\n",
    "# Calculate sentiment percentages\n",
    "agg_df['pct_positive'] = (agg_df['num_positive'] / agg_df['total_segments'] * 100).round(2)\n",
    "agg_df['pct_negative'] = (agg_df['num_negative'] / agg_df['total_segments'] * 100).round(2)\n",
    "agg_df['avg_confidence'] = agg_df['avg_confidence'].round(4)\n",
    "\n",
    "# Calculate sentiment score: range from -1 (all negative) to +1 (all positive)\n",
    "# Formula: (num_positive - num_negative) / total_segments\n",
    "agg_df['sentiment_score'] = (\n",
    "    (agg_df['num_positive'] - agg_df['num_negative']) / agg_df['total_segments']\n",
    ").round(4)\n",
    "\n",
    "# Determine dominant sentiment for each (restaurant, aspect) pair\n",
    "agg_df['dominant_sentiment'] = agg_df.apply(\n",
    "    lambda row: 'positive' if row['num_positive'] > row['num_negative'] \n",
    "                else ('negative' if row['num_negative'] > row['num_positive'] else 'neutral'),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Calculate high confidence ratio\n",
    "agg_df['pct_high_confidence'] = (\n",
    "    agg_df['high_confidence_count'] / agg_df['total_segments'] * 100\n",
    ").round(2)\n",
    "\n",
    "print(f\"  âœ“ Aggregation complete\")\n",
    "print(f\"    Unique restaurants: {agg_df['Restaurant_Name'].nunique():,}\")\n",
    "print(f\"    Unique aspects:     {agg_df['aspect'].nunique()}\")\n",
    "print(f\"    Total (restaurant, aspect) pairs: {len(agg_df):,}\")\n",
    "\n",
    "print(f\"\\n  Sample aggregates:\")\n",
    "print(agg_df.head(10).to_string(index=False))\n",
    "\n",
    "# Save aggregated data\n",
    "agg_df.to_csv(CFG.restaurant_aggregates_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"\\n  âœ“ Restaurant-aspect aggregates saved\")\n",
    "print(f\"    Path: {CFG.restaurant_aggregates_path}\")\n",
    "print(f\"    Size: {os.path.getsize(CFG.restaurant_aggregates_path) / 1024:.2f} KB\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf48d9c0",
   "metadata": {},
   "source": [
    "# STAGE 10: Prepare Kano Model Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94dfb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Prepare Kano Model Input (Aspect-Level Sentiment Distribution)\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PREPARING KANO MODEL INPUT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Kano Model requires understanding sentiment distribution per aspect GLOBALLY\n",
    "# (across all restaurants) to categorize aspects into:\n",
    "#   - Must-Have: Negative sentiment has high impact on satisfaction\n",
    "#   - Performance: Linear relationship (more positive = better)\n",
    "#   - Attractive: Positive sentiment delights, absence doesn't hurt\n",
    "#   - Indifferent: Sentiment doesn't affect satisfaction\n",
    "\n",
    "# Aggregate by aspect only (across all restaurants)\n",
    "kano_df = df_exploded.groupby('aspect').agg(\n",
    "    total_mentions=('Segment', 'count'),\n",
    "    num_positive=('predicted_sentiment_id', lambda x: (x == 1).sum()),\n",
    "    num_negative=('predicted_sentiment_id', lambda x: (x == 0).sum()),\n",
    "    avg_confidence=('confidence', 'mean'),\n",
    ").reset_index()\n",
    "\n",
    "# Calculate percentages\n",
    "kano_df['pct_positive'] = (kano_df['num_positive'] / kano_df['total_mentions'] * 100).round(2)\n",
    "kano_df['pct_negative'] = (kano_df['num_negative'] / kano_df['total_mentions'] * 100).round(2)\n",
    "kano_df['avg_confidence'] = kano_df['avg_confidence'].round(4)\n",
    "\n",
    "# Calculate sentiment polarity (how skewed the aspect is)\n",
    "# Range: -1 (all negative) to +1 (all positive)\n",
    "kano_df['sentiment_polarity'] = (\n",
    "    (kano_df['num_positive'] - kano_df['num_negative']) / kano_df['total_mentions']\n",
    ").round(4)\n",
    "\n",
    "# Sort by total mentions (most discussed aspects)\n",
    "kano_df = kano_df.sort_values('total_mentions', ascending=False)\n",
    "\n",
    "print(f\"  âœ“ Kano Model input prepared\")\n",
    "print(f\"    Total aspects: {len(kano_df)}\")\n",
    "\n",
    "print(f\"\\n  Aspect Sentiment Distribution (for Kano categorization):\")\n",
    "print(kano_df.to_string(index=False))\n",
    "\n",
    "# Save Kano input\n",
    "kano_df.to_csv(CFG.kano_input_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"\\n  âœ“ Kano Model input saved\")\n",
    "print(f\"    Path: {CFG.kano_input_path}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Interpretation guide for Kano categorization\n",
    "print(f\"\\n  KANO MODEL CATEGORIZATION GUIDE:\")\n",
    "print(f\"  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print(f\"  Use this data to categorize aspects in Power BI DAX:\")\n",
    "print(f\"\")\n",
    "print(f\"  1. MUST-HAVE (Basic Needs):\")\n",
    "print(f\"     â†’ High negative % + High total mentions\")\n",
    "print(f\"     â†’ Absence causes dissatisfaction, presence is expected\")\n",
    "print(f\"     â†’ Example: FOOD, SERVICE, HALAL COMPLIANCE\")\n",
    "print(f\"\")\n",
    "print(f\"  2. PERFORMANCE (Proportional Satisfaction):\")\n",
    "print(f\"     â†’ Balanced negative/positive %\")\n",
    "print(f\"     â†’ More = Better, Less = Worse\")\n",
    "print(f\"     â†’ Example: VALUE, AMBIENCE\")\n",
    "print(f\"\")\n",
    "print(f\"  3. ATTRACTIVE (Delighters):\")\n",
    "print(f\"     â†’ High positive % + Lower total mentions\")\n",
    "print(f\"     â†’ Presence delights, absence doesn't hurt\")\n",
    "print(f\"     â†’ Example: AUTHENTICITY & LOCAL VIBE, LOYALTY\")\n",
    "print(f\"\")\n",
    "print(f\"  4. INDIFFERENT:\")\n",
    "print(f\"     â†’ Low sentiment polarity + Low mentions\")\n",
    "print(f\"     â†’ Doesn't affect satisfaction\")\n",
    "print(f\"  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b65ed7a",
   "metadata": {},
   "source": [
    "# STAGE 11: Generate Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b5479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Generate Summary Statistics (for quick validation & thesis reporting)\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"GENERATING SUMMARY STATISTICS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "summary_stats = {\n",
    "    \"data_overview\": {\n",
    "        \"total_reviews\": int(df_exploded['Original_Review_ID'].nunique()),\n",
    "        \"total_restaurants\": int(df_exploded['Restaurant_Name'].nunique()),\n",
    "        \"total_segments\": int(len(df_full)),\n",
    "        \"total_aspect_segment_pairs\": int(len(df_exploded)),\n",
    "        \"unique_aspects\": int(df_exploded['aspect'].nunique()),\n",
    "        \"aspects_list\": sorted(df_exploded['aspect'].unique().tolist()),\n",
    "    },\n",
    "    \n",
    "    \"prediction_distribution\": {\n",
    "        \"positive_predictions\": int((df_exploded['predicted_sentiment'] == 'positive').sum()),\n",
    "        \"negative_predictions\": int((df_exploded['predicted_sentiment'] == 'negative').sum()),\n",
    "        \"pct_positive\": float(round((df_exploded['predicted_sentiment'] == 'positive').mean() * 100, 2)),\n",
    "        \"pct_negative\": float(round((df_exploded['predicted_sentiment'] == 'negative').mean() * 100, 2)),\n",
    "    },\n",
    "    \n",
    "    \"confidence_metrics\": {\n",
    "        \"mean_confidence\": float(round(df_exploded['confidence'].mean(), 4)),\n",
    "        \"median_confidence\": float(round(df_exploded['confidence'].median(), 4)),\n",
    "        \"high_confidence_count\": int(df_exploded['is_high_confidence'].sum()),\n",
    "        \"low_confidence_count\": int((~df_exploded['is_high_confidence']).sum()),\n",
    "        \"pct_high_confidence\": float(round(df_exploded['is_high_confidence'].mean() * 100, 2)),\n",
    "        \"confidence_threshold\": float(CFG.confidence_threshold),\n",
    "    },\n",
    "    \n",
    "    \"per_aspect_summary\": {},\n",
    "    \n",
    "    \"model_info\": {\n",
    "        \"model_name\": CFG.model_name,\n",
    "        \"model_path\": CFG.model_path,\n",
    "        \"batch_size\": CFG.batch_size,\n",
    "        \"max_seq_length\": CFG.max_seq_length,\n",
    "    },\n",
    "    \n",
    "    \"output_files\": {\n",
    "        \"segment_predictions\": CFG.segment_predictions_path,\n",
    "        \"restaurant_aggregates\": CFG.restaurant_aggregates_path,\n",
    "        \"kano_input\": CFG.kano_input_path,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Add per-aspect breakdown\n",
    "for aspect in sorted(df_exploded['aspect'].unique()):\n",
    "    aspect_data = df_exploded[df_exploded['aspect'] == aspect]\n",
    "    summary_stats[\"per_aspect_summary\"][aspect] = {\n",
    "        \"total_mentions\": int(len(aspect_data)),\n",
    "        \"num_positive\": int((aspect_data['predicted_sentiment'] == 'positive').sum()),\n",
    "        \"num_negative\": int((aspect_data['predicted_sentiment'] == 'negative').sum()),\n",
    "        \"pct_positive\": float(round((aspect_data['predicted_sentiment'] == 'positive').mean() * 100, 2)),\n",
    "        \"pct_negative\": float(round((aspect_data['predicted_sentiment'] == 'negative').mean() * 100, 2)),\n",
    "        \"avg_confidence\": float(round(aspect_data['confidence'].mean(), 4)),\n",
    "    }\n",
    "\n",
    "# Save summary as JSON\n",
    "with open(CFG.summary_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(summary_stats, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"  âœ“ Summary statistics saved\")\n",
    "print(f\"    Path: {CFG.summary_path}\")\n",
    "\n",
    "# Print key statistics\n",
    "print(f\"\\n  KEY STATISTICS:\")\n",
    "print(f\"  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print(f\"  Total Reviews:              {summary_stats['data_overview']['total_reviews']:>8,}\")\n",
    "print(f\"  Total Restaurants:          {summary_stats['data_overview']['total_restaurants']:>8,}\")\n",
    "print(f\"  Total Segments:             {summary_stats['data_overview']['total_segments']:>8,}\")\n",
    "print(f\"  Total Aspect-Segment Pairs: {summary_stats['data_overview']['total_aspect_segment_pairs']:>8,}\")\n",
    "print(f\"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "print(f\"  Positive Predictions:       {summary_stats['prediction_distribution']['positive_predictions']:>8,} ({summary_stats['prediction_distribution']['pct_positive']:>5.1f}%)\")\n",
    "print(f\"  Negative Predictions:       {summary_stats['prediction_distribution']['negative_predictions']:>8,} ({summary_stats['prediction_distribution']['pct_negative']:>5.1f}%)\")\n",
    "print(f\"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "print(f\"  Mean Confidence:            {summary_stats['confidence_metrics']['mean_confidence']:>8.4f}\")\n",
    "print(f\"  High Confidence (>{CFG.confidence_threshold}):   {summary_stats['confidence_metrics']['high_confidence_count']:>8,} ({summary_stats['confidence_metrics']['pct_high_confidence']:>5.1f}%)\")\n",
    "print(f\"  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c3e32b",
   "metadata": {},
   "source": [
    "# STAGE 12: Quick Visualizations (for validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e39eb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Quick Visualizations for Sanity Checks\n",
    "# ==============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 10)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Sentiment Distribution by Aspect\n",
    "aspect_sentiment = df_exploded.groupby(['aspect', 'predicted_sentiment']).size().unstack(fill_value=0)\n",
    "aspect_sentiment_pct = aspect_sentiment.div(aspect_sentiment.sum(axis=1), axis=0) * 100\n",
    "\n",
    "ax1 = axes[0, 0]\n",
    "aspect_sentiment_pct.plot(kind='barh', stacked=True, color=['#e74c3c', '#2ecc71'], ax=ax1)\n",
    "ax1.set_title('Sentiment Distribution by Aspect (%)', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Percentage (%)')\n",
    "ax1.set_ylabel('Aspect')\n",
    "ax1.legend(title='Sentiment', labels=['Negative', 'Positive'])\n",
    "\n",
    "# 2. Confidence Score Distribution\n",
    "ax2 = axes[0, 1]\n",
    "ax2.hist(df_exploded['confidence'], bins=50, color='#3498db', edgecolor='black', alpha=0.7)\n",
    "ax2.axvline(CFG.confidence_threshold, color='red', linestyle='--', linewidth=2, label=f'Threshold ({CFG.confidence_threshold})')\n",
    "ax2.set_title('Confidence Score Distribution', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('Confidence Score')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.legend()\n",
    "\n",
    "# 3. Aspect Mention Frequency\n",
    "ax3 = axes[1, 0]\n",
    "aspect_counts = df_exploded['aspect'].value_counts()\n",
    "aspect_counts.plot(kind='barh', color='#9b59b6', ax=ax3)\n",
    "ax3.set_title('Aspect Mention Frequency', fontsize=12, fontweight='bold')\n",
    "ax3.set_xlabel('Number of Mentions')\n",
    "ax3.set_ylabel('Aspect')\n",
    "\n",
    "# 4. Sentiment Polarity by Aspect (for Kano Model)\n",
    "ax4 = axes[1, 1]\n",
    "kano_df_sorted = kano_df.sort_values('sentiment_polarity')\n",
    "colors = ['#e74c3c' if x < 0 else '#2ecc71' for x in kano_df_sorted['sentiment_polarity']]\n",
    "ax4.barh(kano_df_sorted['aspect'], kano_df_sorted['sentiment_polarity'], color=colors)\n",
    "ax4.axvline(0, color='black', linewidth=1)\n",
    "ax4.set_title('Sentiment Polarity by Aspect (Kano Input)', fontsize=12, fontweight='bold')\n",
    "ax4.set_xlabel('Sentiment Polarity (-1 to +1)')\n",
    "ax4.set_ylabel('Aspect')\n",
    "ax4.set_xlim(-1, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(CFG.output_dir, 'sentiment_analysis_overview.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nâœ“ Visualizations saved to: {os.path.join(CFG.output_dir, 'sentiment_analysis_overview.png')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c9a533",
   "metadata": {},
   "source": [
    "# âœ… INFERENCE COMPLETE - Next Steps for Power BI\n",
    "\n",
    "## Generated Files (All saved to `Dataset/` folder):\n",
    "\n",
    "1. **`segment_level_predictions.csv`** (Detailed)\n",
    "   - One row per (segment, aspect) pair\n",
    "   - Includes: segment text, aspect, predicted sentiment, probabilities, confidence\n",
    "   - Use for: Drill-down analysis, finding specific mentions\n",
    "\n",
    "2. **`restaurant_aspect_aggregates.csv`** (Summary)\n",
    "   - One row per (restaurant, aspect) combination\n",
    "   - Includes: sentiment counts, percentages, sentiment score (-1 to +1)\n",
    "   - Use for: Restaurant profiling, comparative analysis\n",
    "\n",
    "3. **`kano_model_input.csv`** (Strategic)\n",
    "   - One row per aspect (across all restaurants)\n",
    "   - Includes: total mentions, sentiment distribution, polarity\n",
    "   - Use for: Kano Model categorization (Must-Have vs Attractive)\n",
    "\n",
    "4. **`prediction_summary.json`** (Metadata)\n",
    "   - Overall statistics for validation and thesis reporting\n",
    "\n",
    "---\n",
    "\n",
    "## Power BI Integration Steps:\n",
    "\n",
    "### 1. Load Data into Power BI\n",
    "```dax\n",
    "// Load restaurant aggregates as main table\n",
    "Source = Csv.Document(File.Contents(\"Dataset/restaurant_aspect_aggregates.csv\"))\n",
    "```\n",
    "\n",
    "### 2. Create Kano Model DAX Calculated Column\n",
    "```dax\n",
    "Kano_Category = \n",
    "VAR TotalMentions = [total_segments]\n",
    "VAR PositivePct = [pct_positive]\n",
    "VAR NegativePct = [pct_negative]\n",
    "RETURN\n",
    "    SWITCH(\n",
    "        TRUE(),\n",
    "        NegativePct > 30 && TotalMentions > 100, \"Must-Have\",\n",
    "        PositivePct > 70 && TotalMentions < 50, \"Attractive\",\n",
    "        PositivePct > 40 && NegativePct > 20, \"Performance\",\n",
    "        \"Indifferent\"\n",
    "    )\n",
    "```\n",
    "\n",
    "### 3. Key Visualizations to Create:\n",
    "- **Sentiment Heatmap**: Restaurant (rows) Ã— Aspect (columns) colored by sentiment_score\n",
    "- **Kano Model Quadrant**: Scatter plot with sentiment_polarity vs. total_mentions\n",
    "- **Top Negative Aspects by Restaurant**: Bar chart filtered by `pct_negative > 40`\n",
    "- **Confidence Filter**: Slicer for `is_high_confidence` to show only reliable predictions\n",
    "\n",
    "---\n",
    "\n",
    "## âš ï¸ Important Notes:\n",
    "\n",
    "1. **Low Confidence Predictions**: \n",
    "   - Predictions with confidence < 0.6 should be flagged for manual review\n",
    "   - These are visible in the `is_high_confidence` column\n",
    "\n",
    "2. **Multi-Aspect Segments**:\n",
    "   - Each segment can appear multiple times (once per aspect)\n",
    "   - Use `Original_Review_ID` to track back to full reviews\n",
    "\n",
    "3. **Data Validation**:\n",
    "   - Check `prediction_summary.json` for overall statistics\n",
    "   - Verify sentiment distribution matches expectations (~90% positive from weak labels)\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Ready for Dashboard Creation!\n",
    "All prediction data is now available in CSV format for Power BI import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11469810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Empirical Analysis: Confidence Threshold Trade-offs\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CONFIDENCE THRESHOLD ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nAcademic References:\")\n",
    "print(\"  [1] Hendrycks & Gimpel (2017) - Baseline for Detecting Misclassified Examples\")\n",
    "print(\"  [2] Guo et al. (2017) - On Calibration of Modern Neural Networks\")\n",
    "print(\"  [3] Ratner et al. (2016) - Data Programming (Weak Supervision)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Define threshold candidates\n",
    "thresholds = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "print(f\"\\n{'Threshold':<12} {'High Conf %':<15} {'Flagged %':<15} {'Mean Conf':<15} {'Interpretation'}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "threshold_analysis = []\n",
    "\n",
    "for thresh in thresholds:\n",
    "    high_conf_mask = df_exploded['confidence'] >= thresh\n",
    "    pct_high = (high_conf_mask.sum() / len(df_exploded)) * 100\n",
    "    pct_flagged = 100 - pct_high\n",
    "    mean_conf = df_exploded[high_conf_mask]['confidence'].mean() if high_conf_mask.sum() > 0 else 0\n",
    "    \n",
    "    # Interpretation based on literature\n",
    "    if thresh <= 0.6:\n",
    "        interpret = \"Liberal (High Recall)\"\n",
    "    elif thresh <= 0.75:\n",
    "        interpret = \"Balanced (Recommended)\"\n",
    "    elif thresh <= 0.85:\n",
    "        interpret = \"Conservative\"\n",
    "    else:\n",
    "        interpret = \"Very Conservative\"\n",
    "    \n",
    "    threshold_analysis.append({\n",
    "        'threshold': thresh,\n",
    "        'pct_high_conf': round(pct_high, 2),\n",
    "        'pct_flagged': round(pct_flagged, 2),\n",
    "        'mean_conf': round(mean_conf, 4),\n",
    "        'interpretation': interpret\n",
    "    })\n",
    "    \n",
    "    print(f\"{thresh:<12.1f} {pct_high:<15.1f} {pct_flagged:<15.1f} {mean_conf:<15.4f} {interpret}\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Confidence distribution percentiles\n",
    "print(f\"\\n  Confidence Score Percentiles:\")\n",
    "percentiles = [10, 25, 50, 75, 90, 95, 99]\n",
    "for p in percentiles:\n",
    "    val = np.percentile(df_exploded['confidence'], p)\n",
    "    print(f\"    {p:>2}th percentile: {val:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RECOMMENDATION (Based on Guo et al. 2017 & Weak Supervision Literature):\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"  Current Threshold: {CFG.confidence_threshold}\")\n",
    "print(f\"  High Confidence:   {(df_exploded['confidence'] >= CFG.confidence_threshold).sum():,} predictions ({(df_exploded['confidence'] >= CFG.confidence_threshold).mean()*100:.1f}%)\")\n",
    "print(f\"  Flagged for Review: {(df_exploded['confidence'] < CFG.confidence_threshold).sum():,} predictions ({(df_exploded['confidence'] < CFG.confidence_threshold).mean()*100:.1f}%)\")\n",
    "print(f\"\\n  âœ“ For Power BI Dashboard: 0.7-0.8 provides good balance\")\n",
    "print(f\"  âœ“ For High-Stakes Decisions: Use â‰¥0.8 and manually review flagged cases\")\n",
    "print(f\"  âœ“ For Maximum Coverage: Use â‰¥0.6 but note increased noise risk\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create confidence distribution visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left plot: Confidence histogram with threshold line\n",
    "ax1 = axes[0]\n",
    "ax1.hist(df_exploded['confidence'], bins=50, color='#3498db', edgecolor='black', alpha=0.7)\n",
    "ax1.axvline(CFG.confidence_threshold, color='red', linestyle='--', linewidth=2, \n",
    "            label=f'Current Threshold ({CFG.confidence_threshold})')\n",
    "ax1.axvline(0.8, color='orange', linestyle=':', linewidth=2, label='Conservative (0.8)')\n",
    "ax1.set_title('Confidence Score Distribution', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Confidence Score')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Right plot: Coverage vs Threshold trade-off\n",
    "ax2 = axes[1]\n",
    "thresh_range = np.linspace(0.5, 0.95, 50)\n",
    "coverage = [(df_exploded['confidence'] >= t).mean() * 100 for t in thresh_range]\n",
    "ax2.plot(thresh_range, coverage, linewidth=2, color='#2ecc71')\n",
    "ax2.axvline(CFG.confidence_threshold, color='red', linestyle='--', linewidth=2, \n",
    "            label=f'Current ({CFG.confidence_threshold})')\n",
    "ax2.axhline(80, color='gray', linestyle=':', alpha=0.5, label='80% Coverage')\n",
    "ax2.set_title('Coverage vs Confidence Threshold', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('Confidence Threshold')\n",
    "ax2.set_ylabel('Coverage (%)')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "ax2.set_ylim([0, 105])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(CFG.output_dir, 'confidence_threshold_analysis.png'), \n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nâœ“ Analysis saved to: {os.path.join(CFG.output_dir, 'confidence_threshold_analysis.png')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c678f678",
   "metadata": {},
   "source": [
    "# STAGE 13: Merge with Silver Standard for Metadata (State, Category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270f2c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Merge Predictions with Silver Standard Metadata (State, Category)\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MERGING WITH SILVER STANDARD FOR METADATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load silver standard (contains state, category, restaurant name)\n",
    "#silver_path = r\"C:\\Users\\Ong Hui Ling\\Dropbox\\PC\\Documents\\Github\\Aspect-Based-Sentiment-Analysis\\Dataset\\silver_std.pkl\"\n",
    "silver_path = r\"\\content\\drive\\MyDrive\\Aspect-Based-Sentiment-Analysis\\Dataset\\silver_std.pkl\"\n",
    "\n",
    "df_silver = pd.read_pickle(silver_path)\n",
    "print(f\"  âœ“ Silver standard loaded: {len(df_silver):,} reviews\")\n",
    "\n",
    "# Extract unique review ID and restaurant metadata\n",
    "# silver_std has one row per review, aspect_categorization has multiple rows\n",
    "# (segments per review) \n",
    "df_silver_meta = df_silver[[\n",
    "    'reviewID',           # Review ID\n",
    "    'name',               # Restaurant name\n",
    "    'state',              # State (for strategic analysis)\n",
    "    'main_category',      # Main category (e.g., Mamak, Fine Dining)\n",
    "    'sub_category',       # Sub category\n",
    "    'place_overall_rating',  # Restaurant overall rating (context)\n",
    "    'user_review_rating'     # Star rating (weak label source)\n",
    "]].drop_duplicates(subset=['reviewID']).reset_index(drop=True)\n",
    "\n",
    "print(f\"  âœ“ Metadata extracted: {len(df_silver_meta):,} unique reviews\")\n",
    "\n",
    "# Merge with predictions by matching review ID using Full_Review as proxy\n",
    "# (Since aspect_categorization has full review text, we can match)\n",
    "# Actually, let's use the fact that Original_Review_ID likely corresponds to a sequence\n",
    "# \n",
    "# Better approach: Match by Full_Review text from aspect_categorization\n",
    "# But this is slow. Instead, let's check if Original_Review_ID appears in silver_std\n",
    "\n",
    "print(f\"\\n  Data Quality Check:\")\n",
    "print(f\"    aspect_exploded rows: {len(df_exploded):,}\")\n",
    "print(f\"    unique reviews in exploded: {df_exploded['Original_Review_ID'].nunique():,}\")\n",
    "\n",
    "# For this macro dataset, we'll take a simpler approach:\n",
    "# Group silver_std by main_category and state, then assign to aspect predictions\n",
    "# This works because aspect_categorization_refined is a SUBSET of silver_std\n",
    "\n",
    "# Create mapping: For each review, find its state and category from silver_std\n",
    "# using the review text as key (since Original_Review_ID may not align)\n",
    "\n",
    "# Alternative: Since both have the full review text, merge on that\n",
    "print(f\"\\n  Attempting merge on Full_Review text...\")\n",
    "\n",
    "df_exploded_with_meta = df_exploded.merge(\n",
    "    df_silver[[\n",
    "        'text',               # Full review text\n",
    "        'state',\n",
    "        'main_category',\n",
    "        'sub_category',\n",
    "        'name',               # Restaurant name\n",
    "        'user_review_rating'  # Star rating\n",
    "    ]],\n",
    "    left_on='Original_Review_ID',\n",
    "    right_on='reviewID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Check merge success\n",
    "merge_success = df_exploded_with_meta['state'].notna().sum()\n",
    "print(f\"  âœ“ Merge result: {merge_success:,} / {len(df_exploded_with_meta):,} rows matched ({merge_success/len(df_exploded_with_meta)*100:.1f}%)\")\n",
    "\n",
    "if merge_success < len(df_exploded_with_meta) * 0.9:\n",
    "    print(f\"\\n  âš ï¸  WARNING: Only {merge_success/len(df_exploded_with_meta)*100:.1f}% rows matched!\")\n",
    "    print(f\"      This suggests Original_Review_ID and text don't align perfectly.\")\n",
    "    print(f\"      Please verify the data source.\")\n",
    "\n",
    "# Drop the text column (no longer needed)\n",
    "df_exploded_with_meta = df_exploded_with_meta.drop(columns=['text'], errors='ignore')\n",
    "\n",
    "print(f\"\\n  âœ“ State distribution:\")\n",
    "state_counts = df_exploded_with_meta['state'].value_counts()\n",
    "for state, count in state_counts.head(10).items():\n",
    "    if pd.notna(state):\n",
    "        print(f\"    {state:<20}: {count:>6,} segments\")\n",
    "\n",
    "print(f\"\\n  âœ“ Main category distribution:\")\n",
    "cat_counts = df_exploded_with_meta['main_category'].value_counts()\n",
    "for cat, count in cat_counts.head(10).items():\n",
    "    if pd.notna(cat):\n",
    "        print(f\"    {cat:<20}: {count:>6,} segments\")\n",
    "\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e962db4",
   "metadata": {},
   "source": [
    "# STAGE 14: State-Level Aggregation (For Government Strategic Planning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e68e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# State-Level Aggregation (Critical for Government Tourism Boards)\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STATE-LEVEL SENTIMENT AGGREGATION\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nWhy State-Level?\")\n",
    "print(\"  - Government tourism strategies operate at state level\")\n",
    "print(\"  - Allows regional benchmarking (which states excel/lag)\")\n",
    "print(\"  - Supports resource allocation decisions\")\n",
    "print(\"  - Macro dataset covers ALL states â†’ comprehensive coverage\")\n",
    "\n",
    "# Group by state and aspect\n",
    "state_agg = df_exploded_with_meta.dropna(subset=['state']).groupby(['state', 'aspect']).agg(\n",
    "    total_segments=('Segment', 'count'),\n",
    "    num_positive=('predicted_sentiment_id', lambda x: (x == 1).sum()),\n",
    "    num_negative=('predicted_sentiment_id', lambda x: (x == 0).sum()),\n",
    "    avg_confidence=('confidence', 'mean'),\n",
    "    high_confidence_count=('is_high_confidence', 'sum'),\n",
    "    num_restaurants=('name', 'nunique'),\n",
    ").reset_index()\n",
    "\n",
    "# Calculate percentages and sentiment score\n",
    "state_agg['pct_positive'] = (state_agg['num_positive'] / state_agg['total_segments'] * 100).round(2)\n",
    "state_agg['pct_negative'] = (state_agg['num_negative'] / state_agg['total_segments'] * 100).round(2)\n",
    "state_agg['sentiment_score'] = (\n",
    "    (state_agg['num_positive'] - state_agg['num_negative']) / state_agg['total_segments']\n",
    ").round(4)\n",
    "state_agg['avg_confidence'] = state_agg['avg_confidence'].round(4)\n",
    "state_agg['pct_high_confidence'] = (\n",
    "    state_agg['high_confidence_count'] / state_agg['total_segments'] * 100\n",
    ").round(2)\n",
    "\n",
    "# Sort by popularity (most discussed aspects per state)\n",
    "state_agg = state_agg.sort_values(['state', 'total_segments'], ascending=[True, False])\n",
    "\n",
    "# Output path\n",
    "state_agg_path = os.path.join(CFG.output_dir, \"state_level_summary.csv\")\n",
    "state_agg.to_csv(state_agg_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"\\n  âœ“ State-level aggregation complete\")\n",
    "print(f\"    Rows: {len(state_agg):,} (state Ã— aspect combinations)\")\n",
    "print(f\"    States covered: {state_agg['state'].nunique()}\")\n",
    "print(f\"    Aspects per state: {state_agg.groupby('state').size().mean():.1f}\")\n",
    "print(f\"    Saved to: {state_agg_path}\")\n",
    "\n",
    "print(f\"\\n  Top Negative Aspects by State (pct_negative > 20%):\")\n",
    "print(\"  \" + \"=\" * 66)\n",
    "for state in sorted(state_agg['state'].unique()):\n",
    "    state_data = state_agg[state_agg['state'] == state].nlargest(3, 'pct_negative')\n",
    "    if len(state_data) > 0:\n",
    "        worst = state_data.iloc[0]\n",
    "        print(f\"  {state:<20}: {worst['aspect']:<25} ({worst['pct_negative']:>5.1f}% negative)\")\n",
    "\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2636f82",
   "metadata": {},
   "source": [
    "# STAGE 15: Category-Level Aggregation (Restaurant Type Insights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac16f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Category-Level Aggregation (Restaurant Type Performance)\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CATEGORY-LEVEL SENTIMENT AGGREGATION\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nWhy Category-Level?\")\n",
    "print(\"  - Compare performance across restaurant types (e.g., Mamak vs Fine Dining)\")\n",
    "print(\"  - Identify category-specific pain points\")\n",
    "print(\"  - Support category-specific improvement initiatives\")\n",
    "print(\"  - Benchmark category standards\")\n",
    "\n",
    "# Group by main_category and aspect\n",
    "category_agg = df_exploded_with_meta.dropna(subset=['sub_category']).groupby(['main_category', 'aspect']).agg(\n",
    "    total_segments=('Segment', 'count'),\n",
    "    num_positive=('predicted_sentiment_id', lambda x: (x == 1).sum()),\n",
    "    num_negative=('predicted_sentiment_id', lambda x: (x == 0).sum()),\n",
    "    avg_confidence=('confidence', 'mean'),\n",
    "    high_confidence_count=('is_high_confidence', 'sum'),\n",
    "    num_restaurants=('name', 'nunique'),\n",
    ").reset_index()\n",
    "\n",
    "# Calculate percentages and sentiment score\n",
    "category_agg['pct_positive'] = (category_agg['num_positive'] / category_agg['total_segments'] * 100).round(2)\n",
    "category_agg['pct_negative'] = (category_agg['num_negative'] / category_agg['total_segments'] * 100).round(2)\n",
    "category_agg['sentiment_score'] = (\n",
    "    (category_agg['num_positive'] - category_agg['num_negative']) / category_agg['total_segments']\n",
    ").round(4)\n",
    "category_agg['avg_confidence'] = category_agg['avg_confidence'].round(4)\n",
    "category_agg['pct_high_confidence'] = (\n",
    "    category_agg['high_confidence_count'] / category_agg['total_segments'] * 100\n",
    ").round(2)\n",
    "\n",
    "# Sort by category and segments\n",
    "category_agg = category_agg.sort_values(['main_category', 'total_segments'], ascending=[True, False])\n",
    "\n",
    "# Output path\n",
    "category_agg_path = os.path.join(CFG.output_dir, \"category_level_summary.csv\")\n",
    "category_agg.to_csv(category_agg_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"\\n  âœ“ Category-level aggregation complete\")\n",
    "print(f\"    Rows: {len(category_agg):,} (category Ã— aspect combinations)\")\n",
    "print(f\"    Categories: {category_agg['main_category'].nunique()}\")\n",
    "\n",
    "print(f\"\\n  Categories covered:\")\n",
    "for cat in sorted(category_agg['main_category'].unique()):\n",
    "    cat_data = category_agg[category_agg['main_category'] == cat]\n",
    "    total_seg = cat_data['total_segments'].sum()\n",
    "    num_rest = cat_data['num_restaurants'].sum()\n",
    "    print(f\"    {cat:<30}: {total_seg:>6,} segments from {num_rest:>4,} restaurants\")\n",
    "\n",
    "print(f\"\\n  Category Performance (avg sentiment across all aspects):\")\n",
    "print(\"  \" + \"=\" * 60)\n",
    "cat_performance = category_agg.groupby('main_category').agg(\n",
    "    avg_sentiment_score=('sentiment_score', 'mean'),\n",
    "    avg_pct_positive=('pct_positive', 'mean'),\n",
    "    total_segments=('total_segments', 'sum'),\n",
    ").sort_values('avg_sentiment_score', ascending=False)\n",
    "\n",
    "for cat, row in cat_performance.iterrows():\n",
    "    print(f\"  {cat:<30}: {row['avg_sentiment_score']:>7.4f} (+{row['avg_pct_positive']:>5.1f}%) [{int(row['total_segments']):>6,} segments]\")\n",
    "\n",
    "print(f\"\\n  Saved to: {category_agg_path}\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20af3d2",
   "metadata": {},
   "source": [
    "# STAGE 16: State Ã— Category Matrix (Strategic Heatmap Input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcbb358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# State Ã— Category Matrix (For Government Dashboard)\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STATE Ã— CATEGORY MATRIX AGGREGATION\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nWhy State Ã— Category?\")\n",
    "print(\"  - See which restaurant types perform best in each state\")\n",
    "print(\"  - Identify regional disparities (e.g., Mamak weak in State X)\")\n",
    "print(\"  - Supports policy targeting (e.g., 'improve Mamak service in Johor')\")\n",
    "print(\"  - Enable Power BI heatmap visualizations\")\n",
    "\n",
    "# Group by state, main_category, and aspect\n",
    "state_cat_agg = df_exploded_with_meta.dropna(subset=['state', 'main_category']).groupby(\n",
    "    ['state', 'main_category', 'aspect']\n",
    ").agg(\n",
    "    total_segments=('Segment', 'count'),\n",
    "    num_positive=('predicted_sentiment_id', lambda x: (x == 1).sum()),\n",
    "    num_negative=('predicted_sentiment_id', lambda x: (x == 0).sum()),\n",
    "    avg_confidence=('confidence', 'mean'),\n",
    "    num_restaurants=('name', 'nunique'),\n",
    ").reset_index()\n",
    "\n",
    "# Calculate metrics\n",
    "state_cat_agg['pct_positive'] = (state_cat_agg['num_positive'] / state_cat_agg['total_segments'] * 100).round(2)\n",
    "state_cat_agg['pct_negative'] = (state_cat_agg['num_negative'] / state_cat_agg['total_segments'] * 100).round(2)\n",
    "state_cat_agg['sentiment_score'] = (\n",
    "    (state_cat_agg['num_positive'] - state_cat_agg['num_negative']) / state_cat_agg['total_segments']\n",
    ").round(4)\n",
    "state_cat_agg['avg_confidence'] = state_cat_agg['avg_confidence'].round(4)\n",
    "\n",
    "# Sort for readability\n",
    "state_cat_agg = state_cat_agg.sort_values(['state', 'main_category', 'total_segments'], ascending=[True, True, False])\n",
    "\n",
    "# Output path\n",
    "state_cat_path = os.path.join(CFG.output_dir, \"state_category_summary.csv\")\n",
    "state_cat_agg.to_csv(state_cat_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"\\n  âœ“ State Ã— Category aggregation complete\")\n",
    "print(f\"    Rows: {len(state_cat_agg):,} (state Ã— category Ã— aspect)\")\n",
    "print(f\"    States: {state_cat_agg['state'].nunique()}\")\n",
    "print(f\"    Categories: {state_cat_agg['main_category'].nunique()}\")\n",
    "print(f\"    Total combinations: {state_cat_agg['state'].nunique() * state_cat_agg['main_category'].nunique()}\")\n",
    "print(f\"    Saved to: {state_cat_path}\")\n",
    "\n",
    "# Summary: Best and Worst State-Category combinations\n",
    "print(f\"\\n  TOP 10 Best Performing (State, Category) Combinations:\")\n",
    "print(\"  \" + \"=\" * 60)\n",
    "best_combos = state_cat_agg.groupby(['state', 'main_category']).agg({\n",
    "    'sentiment_score': 'mean',\n",
    "    'total_segments': 'sum',\n",
    "    'num_restaurants': 'sum'\n",
    "}).sort_values('sentiment_score', ascending=False).head(10)\n",
    "\n",
    "for (state, cat), row in best_combos.iterrows():\n",
    "    print(f\"  {state:<20} Ã— {cat:<20}: {row['sentiment_score']:>7.4f} ({int(row['total_segments']):>6,} segs)\")\n",
    "\n",
    "print(f\"\\n  TOP 10 Worst Performing (State, Category) Combinations:\")\n",
    "print(\"  \" + \"=\" * 60)\n",
    "worst_combos = state_cat_agg.groupby(['state', 'main_category']).agg({\n",
    "    'sentiment_score': 'mean',\n",
    "    'total_segments': 'sum',\n",
    "    'num_restaurants': 'sum'\n",
    "}).sort_values('sentiment_score', ascending=True).head(10)\n",
    "\n",
    "for (state, cat), row in worst_combos.iterrows():\n",
    "    print(f\"  {state:<20} Ã— {cat:<20}: {row['sentiment_score']:>7.4f} ({int(row['total_segments']):>6,} segs)\")\n",
    "\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f892653b",
   "metadata": {},
   "source": [
    "# âœ… GOVERNMENT-LEVEL AGGREGATIONS COMPLETE\n",
    "\n",
    "## Strategic Output Files Generated\n",
    "\n",
    "### For Government Tourism Boards & Stakeholders:\n",
    "\n",
    "**1. `state_level_summary.csv`** â­ PRIMARY\n",
    "   - **Rows**: State Ã— Aspect combinations\n",
    "   - **Use case**: Regional performance benchmarking\n",
    "   - **Key columns**: \n",
    "     - `state`, `aspect`, `total_segments`, `pct_positive`, `pct_negative`, `sentiment_score`\n",
    "   - **Dashboard**: State selector â†’ Aspect heatmap â†’ Identify regional weak points\n",
    "\n",
    "**2. `category_level_summary.csv`** â­ SECONDARY\n",
    "   - **Rows**: Restaurant Category Ã— Aspect combinations\n",
    "   - **Use case**: Understand performance by restaurant type\n",
    "   - **Examples**: \n",
    "     - How do Mamak restaurants perform on SERVICE?\n",
    "     - Are Fine Dining restaurants better at AMBIENCE?\n",
    "   - **Dashboard**: Category selector â†’ Aspect performance â†’ Comparative analysis\n",
    "\n",
    "**3. `state_category_summary.csv`** â­ DETAILED\n",
    "   - **Rows**: State Ã— Category Ã— Aspect combinations (most granular)\n",
    "   - **Use case**: Pinpoint policy targets\n",
    "   - **Example insights**:\n",
    "     - \"Mamak restaurants in Johor need SERVICE training\"\n",
    "     - \"Fine Dining in Selangor excels at AMBIENCE\"\n",
    "   - **Dashboard**: State Ã— Category filter â†’ Heatmap visualization\n",
    "\n",
    "---\n",
    "\n",
    "## Power BI Implementation Strategy\n",
    "\n",
    "### Dashboard 1: Regional Benchmarking (For Government)\n",
    "```\n",
    "Top Level: State Selector (Slicer)\n",
    "â”œâ”€ Visualization 1: Aspect Sentiment Heatmap (State Ã— Aspect)\n",
    "â”‚  â”” Color by sentiment_score (-1 to +1)\n",
    "â”œâ”€ Visualization 2: Top 3 Weak Aspects by State\n",
    "â”‚  â”” Filter: pct_negative > 25%\n",
    "â””â”€ Visualization 3: Restaurants in State\n",
    "   â”” Ranking by category health\n",
    "```\n",
    "\n",
    "**DAX Example:**\n",
    "```dax\n",
    "State_Sentiment_Score = \n",
    "CALCULATE(\n",
    "    AVERAGE(StateLevel[sentiment_score]),\n",
    "    ALLEXCEPT(StateLevel, StateLevel[state], StateLevel[aspect])\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Dashboard 2: Category Performance (For Industry)\n",
    "```\n",
    "Top Level: Category Selector (Slicer)\n",
    "â”œâ”€ Visualization 1: Aspect Performance Across States\n",
    "â”‚  â”” Line chart: Each state as trend\n",
    "â”œâ”€ Visualization 2: State Rankings by Category\n",
    "â”‚  â”” Ordered by sentiment_score\n",
    "â””â”€ Visualization 3: Confidence by State\n",
    "   â”” Filter low-confidence recommendations\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Dashboard 3: Strategic Hotspots (For Policy)\n",
    "```\n",
    "Main: State Ã— Category Matrix (State Ã— Category Heatmap)\n",
    "â”œâ”€ Row: State (16 Malaysian states)\n",
    "â”œâ”€ Column: Main_Category (Mamak, Fine Dining, etc.)\n",
    "â”œâ”€ Color: Average sentiment_score for that combination\n",
    "â””â”€ Tooltip: total_segments, num_restaurants, pct_positive\n",
    "```\n",
    "\n",
    "**Interpretation:**\n",
    "- **Green cells** âœ… = Good performance (state-category combination healthy)\n",
    "- **Red cells** âŒ = Intervention needed (state-category combination weak)\n",
    "- **Gray cells** ? = Low sample size (fewer than 10 segments)\n",
    "\n",
    "---\n",
    "\n",
    "## Example Government Insights\n",
    "\n",
    "### Finding 1: Regional Disparities\n",
    "```\n",
    "State: Selangor\n",
    "  FOOD sentiment: +0.82 (Strong)\n",
    "  SERVICE sentiment: -0.15 (Weak - needs intervention)\n",
    "  \n",
    "Action: Government training programs for restaurant service in Selangor\n",
    "```\n",
    "\n",
    "### Finding 2: Category-Specific Issues\n",
    "```\n",
    "Category: Mamak\n",
    "  VALUE sentiment: -0.45 (Concerning - customers feel overpriced)\n",
    "  \n",
    "Action: Investigate pricing standards, recommend price transparency initiatives\n",
    "```\n",
    "\n",
    "### Finding 3: State Ã— Category Hotspot\n",
    "```\n",
    "State: Johor Ã— Category: Hawker\n",
    "  HALAL_COMPLIANCE sentiment: -0.60 (Critical)\n",
    "  \n",
    "Action: Urgent: Halal certification audit in Johor hawker stalls\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## File Organization\n",
    "\n",
    "```\n",
    "Dataset/\n",
    "â”œâ”€â”€ segment_level_predictions.csv     â† Original (detail)\n",
    "â”œâ”€â”€ restaurant_aspect_aggregates.csv  â† Original (restaurant-level)\n",
    "â”œâ”€â”€ kano_model_input.csv              â† Original (aspects)\n",
    "â”œâ”€â”€ state_level_summary.csv           â† NEW (government primary)\n",
    "â”œâ”€â”€ category_level_summary.csv        â† NEW (industry insights)\n",
    "â”œâ”€â”€ state_category_summary.csv        â† NEW (policy heatmap)\n",
    "â”œâ”€â”€ prediction_summary.json           â† Original (metadata)\n",
    "â””â”€â”€ confidence_threshold_analysis.png â† Original (validation)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Load** `state_level_summary.csv` as main table in Power BI\n",
    "2. **Create slicer** for state selection\n",
    "3. **Build heatmap**: Rows = Aspect, Columns = State, Values = sentiment_score\n",
    "4. **Add filters**: confidence > 0.7 (to show only reliable insights)\n",
    "5. **Create** \"Hotspots\" view using `state_category_summary.csv`\n",
    "6. **Export** to stakeholders with navigation guide\n",
    "\n",
    "**Ready for government presentation! ðŸŽ¯**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
