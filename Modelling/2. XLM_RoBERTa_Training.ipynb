{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca1b1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "================================================================================\n",
    "XLM-RoBERTa Aspect-Based Sentiment Classification\n",
    "================================================================================\n",
    "PROJECT : NLP-Driven ABSA for Gastronomy Tourism Insights in Malaysia\n",
    "PIPELINE: Pipelined-ABSA (Decoupled) — Step 3: Sentiment Classification\n",
    "INPUT   : Dataset/aspect_categorization.pkl   (output of Notebook 5)\n",
    "OUTPUT  : models/xlm_roberta_absa_best.pt     (best checkpoint)\n",
    "          results/training_metrics.json        (loss/acc curves)\n",
    "\n",
    "ACADEMIC JUSTIFICATION\n",
    "----------------------\n",
    "- XLM-RoBERTa (Conneau et al., 2020): Pre-trained on 100 languages including\n",
    "  Malay and Chinese. Superior zero/few-shot cross-lingual transfer vs.\n",
    "  monolingual BERT, critical for Manglish code-switching.\n",
    "- Aspect-Conditioned Input (Sun et al., 2019): We prepend the aspect category\n",
    "  to the segment text as \"[aspect] [SEP] [segment]\". This forces the model to\n",
    "  learn aspect-specific sentiment representations rather than general polarity.\n",
    "- Class-Weighted Loss (Japkowicz & Stephen, 2002): Our dataset is severely\n",
    "  imbalanced (89% positive). We use the inverse-frequency weights computed in\n",
    "  Notebook 4 to prevent the model from trivially predicting \"positive\".\n",
    "- Weak Supervision (Ratner et al., 2016): Star ratings are noisy proxies for\n",
    "  sentiment. The consistency filtering in Notebook 4 already removed the worst\n",
    "  offenders (4.1% noise). Residual noise is tolerable for fine-tuning.\n",
    "================================================================================\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a870b8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ENVIRONMENT CHECK\n",
      "======================================================================\n",
      "  ✗  PyTorch                        NOT INSTALLED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓  HuggingFace Transformers       v4.57.1\n",
      "  ✓  Pandas                         v2.2.3\n",
      "  ✓  NumPy                          v2.2.0\n",
      "  ✓  Scikit-Learn                   v1.5.1\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 53\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     48\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome packages are missing. Install them before continuing.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     49\u001b[0m         )\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cuda_avail \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 53\u001b[0m DEVICE \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_environment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 38\u001b[0m, in \u001b[0;36mcheck_environment\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m         all_ok \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Special check: torch CUDA availability\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     40\u001b[0m cuda_avail \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available()\n\u001b[0;32m     41\u001b[0m device_name \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mget_device_name(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m cuda_avail \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCPU only\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# STAGE 0: Environment & Dependency Verification\n",
    "# ==============================================================================\n",
    "\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "REQUIRED = {\n",
    "    \"torch\": \"PyTorch\",\n",
    "    \"transformers\": \"HuggingFace Transformers\",\n",
    "    \"pandas\": \"Pandas\",\n",
    "    \"numpy\": \"NumPy\",\n",
    "    \"sklearn\": \"Scikit-Learn\",\n",
    "}\n",
    "\n",
    "\n",
    "def check_environment():\n",
    "    \"\"\"Verify all required packages are installed and print versions.\n",
    "\n",
    "    Why:\n",
    "        Explicit environment checks prevent cryptic import errors mid-training,\n",
    "        which is especially costly when running on GPU with long epoch times.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"ENVIRONMENT CHECK\")\n",
    "    print(\"=\" * 70)\n",
    "    all_ok = True\n",
    "    for module_name, display_name in REQUIRED.items():\n",
    "        try:\n",
    "            mod = importlib.import_module(module_name)\n",
    "            version = getattr(mod, \"__version__\", \"unknown\")\n",
    "            print(f\"  ✓  {display_name:<30} v{version}\")\n",
    "        except ImportError:\n",
    "            print(f\"  ✗  {display_name:<30} NOT INSTALLED\")\n",
    "            all_ok = False\n",
    "\n",
    "    # Special check: torch CUDA availability\n",
    "    import torch\n",
    "\n",
    "    cuda_avail = torch.cuda.is_available()\n",
    "    device_name = torch.cuda.get_device_name(0) if cuda_avail else \"CPU only\"\n",
    "    print(f\"\\n  GPU Available: {cuda_avail}  →  {device_name}\")\n",
    "    print(f\"  Python:        {sys.version}\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    if not all_ok:\n",
    "        raise RuntimeError(\n",
    "            \"Some packages are missing. Install them before continuing.\"\n",
    "        )\n",
    "    return torch.device(\"cuda\" if cuda_avail else \"cpu\")\n",
    "\n",
    "\n",
    "DEVICE = check_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80363feb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m; \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available()) \n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch; print(torch.cuda.is_available()) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
