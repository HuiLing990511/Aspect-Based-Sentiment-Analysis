{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51c31026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from thefuzz import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd76a415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_gold = pd.read_csv(r'/content/drive/MyDrive/Aspect-Based-Sentiment-Analysis/Dataset/silver_std.pkl')\n",
    "df_gold = pd.read_csv(r'C:\\Users\\Ong Hui Ling\\Dropbox\\PC\\Documents\\Github\\Aspect-Based-Sentiment-Analysis\\Dataset\\Final_Gold_Standard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f55de25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original_Review_ID</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Manual_Aspect</th>\n",
       "      <th>Manual_Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9734</td>\n",
       "      <td>it took a really long time like it took 1 hour...</td>\n",
       "      <td>['SERVICE', 'VALUE']</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9734</td>\n",
       "      <td>the food is tasty</td>\n",
       "      <td>['FOOD']</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9734</td>\n",
       "      <td>the worker here is also rude</td>\n",
       "      <td>['SERVICE']</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10357</td>\n",
       "      <td>great food</td>\n",
       "      <td>['FOOD']</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10357</td>\n",
       "      <td>nice beer</td>\n",
       "      <td>['NON-HALAL ELEMENTS']</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Original_Review_ID                                            Segment  \\\n",
       "0                9734  it took a really long time like it took 1 hour...   \n",
       "1                9734                                  the food is tasty   \n",
       "2                9734                       the worker here is also rude   \n",
       "3               10357                                         great food   \n",
       "4               10357                                          nice beer   \n",
       "\n",
       "            Manual_Aspect Manual_Sentiment  \n",
       "0    ['SERVICE', 'VALUE']         NEGATIVE  \n",
       "1                ['FOOD']         POSITIVE  \n",
       "2             ['SERVICE']         NEGATIVE  \n",
       "3                ['FOOD']         POSITIVE  \n",
       "4  ['NON-HALAL ELEMENTS']         POSITIVE  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf462d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. THE MASTER MALAYSIAN ASPECT DICTIONARY\n",
    "# ==========================================\n",
    "ASPECT_DICT = {\n",
    "    'FOOD': [\n",
    "        # Taste & Quality\n",
    "        'food', 'taste', 'tasty', 'delicious', 'sedap', 'yummy', 'flavor', 'flavour',\n",
    "        'fresh', 'juicy', 'tender', 'crispy', 'flavorful', 'perfect', \n",
    "        'bland', 'tasteless', 'hambar', 'burnt', 'raw', 'undercooked',\n",
    "        'overcooked', 'soggy', 'stale', 'spoiled', 'terrible', 'awful', 'unappetizing',\n",
    "        'salty', 'masin', 'sweet', 'manis', 'sour', 'masam', 'spicy', 'pedas',\n",
    "        'umami', 'kick', 'wok hei', 'lemak', 'dishes','herbs', 'spices',\n",
    "        'chili', 'chewy', 'shiok','well-fried','dish',\n",
    "\n",
    "        # Specific Dishes & Items\n",
    "        'chicken', 'rice', 'nasi', 'mee', 'noodle', 'soup', 'meat', 'seafood',\n",
    "        'drink', 'beverage', 'coffee', 'tea', 'dessert', 'cake', 'roti', 'sambal',\n",
    "        'kuah', 'goreng', 'nasi lemak', 'char kuey teow', 'roti canai', 'laksa',\n",
    "        'satay', 'rendang', 'dim sum', 'wan tan mee', 'hokkien mee', 'chicken rice',\n",
    "        'nasi kandar', 'banana leaf', 'tomyam', 'cendol', 'teh tarik', 'kopi',\n",
    "        'cook', 'chef', 'latte', 'matcha', 'cheese', 'sauce', 'gravy','beef',\n",
    "        'mutton', 'sushi','macha', 'kek', 'murtabak', 'cincalok','hot dog',\n",
    "        'kerabu', 'bak kut teh', 'yong tau foo', 'naan', 'otak-otak', 'kuih',\n",
    "        'apam', 'chee cheong fun', 'burger', 'biryani', 'ikan', 'ayam', 'watermelon',\n",
    "        'salmon', 'crab', 'oyster', 'fish','omelette', 'juice', 'samosa','snack', 'kangkung',\n",
    "        'pumpkin',\n",
    "\n",
    "        # Meal Times\n",
    "        'lunch', 'dinner', 'breakfast', 'brunch', 'supper', 'meal', 'eating', 'eat',\n",
    "        'makan', 'minum', 'hungry', 'full', 'appetite', 'tapau'\n",
    "    ],\n",
    "\n",
    "    'SERVICE': [\n",
    "        # Speed\n",
    "        'service', 'slow', 'fast', 'laju', 'lambat', 'quick', 'rapid', 'prompt',\n",
    "        'efficient', 'delay', 'wait', 'waiting', 'queue', 'tunggu', 'late', 'long', 'lama',\n",
    "        'minutes'\n",
    "\n",
    "        # Attitude & Staff\n",
    "        'staff', 'waiter', 'waitress', 'manager', 'boss', 'worker', 'crew',\n",
    "        'friendly', 'rude', 'polite', 'kasar', 'mesra', 'helpful', 'attentive',\n",
    "        'welcoming', 'arrogant', 'ignore', 'responsive', 'smiling', 'courteous',\n",
    "        'knowledgeable', 'clueless', 'kantoi', 'slumber', 'server',\n",
    "        'amoi', 'anneh', 'brother', 'abang', 'kakak', 'auntie', 'uncle',\n",
    "        'guy', 'lady', 'personnel', 'team', 'cashier', 'people', 'disrespect', 'thoughtfully',\n",
    "        'thoughtful', 'cheating'\n",
    "    ],\n",
    "\n",
    "    'VALUE': [\n",
    "        # Price & Worth\n",
    "        'price', 'cost', 'expensive', 'cheap', 'mahal', 'murah', 'affordable',\n",
    "        'pricey', 'reasonable', 'worth', 'berbaloi', 'value', 'budget', 'bill',\n",
    "        'ringgit', 'rm', 'charge', 'tax', 'standard', 'cut throat', 'wallet', 'money',\n",
    "        'rip-off', 'bargain', 'overpriced','amount',\n",
    "\n",
    "        # Portion Size\n",
    "        'portion', 'size', 'quantity', 'serving', 'big', 'besar', 'small',\n",
    "        'kecil', 'huge', 'tiny', 'generous', 'stingy', 'banyak', 'sikit'\n",
    "    ],\n",
    "\n",
    "    'LOCATION': [\n",
    "        # Accessibility & Parking\n",
    "        'location', 'loc', 'spot', 'area', 'zone', 'position',\n",
    "        'parking', 'park', 'carpark', 'valet', 'lot','jauh', 'dekat',\n",
    "        'waze', 'map', 'maps', 'direction', 'find', 'locate', 'accessible',\n",
    "        'traffic', 'jam', 'station', 'lrt', 'mrt', 'transport', 'strategic'\n",
    "    ],\n",
    "\n",
    "    'AMBIENCE': [\n",
    "        # Interior & Vibes\n",
    "        'environment', 'ambience', 'atmosphere','decorate', 'relaxed','vibes'\n",
    "        'vibe', 'decor', 'decoration', 'interior', 'aesthetic', 'view', 'scenery',\n",
    "        'comfortable', 'selesa', 'cozy', 'spacious', 'luas', 'sempit', 'cramped',\n",
    "        'relaxing', 'chill', 'instagram', 'instagrammable', 'music', 'happening',\n",
    "        'chillax',\n",
    "\n",
    "        # Comfort & Facilities\n",
    "        'seat', 'seating', 'table', 'chair', 'toilet', 'washroom', 'aircon',\n",
    "        'air conditioning', 'fan', 'ventilation', 'hot', 'panas', 'cold', 'sejuk',\n",
    "        'warm', 'stuffy', 'noise', 'noisy', 'bising', 'loud', 'quiet', 'senyap',\n",
    "        'crowd', 'crowded', 'sesak', 'packed', 'busy','space',\n",
    "\n",
    "         # Cleanliness & Safety\n",
    "        'clean', 'dirty', 'bersih', 'kotor', 'tidy', 'messy', 'spotless',\n",
    "        'filthy', 'hygiene', 'sanitary', 'grimy', 'dusty', 'smell', 'stink',\n",
    "\n",
    "        # Pests & Illness\n",
    "        'fly', 'flies', 'lalat', 'cockroach', 'lipas', 'roach', 'rat', 'tikus',\n",
    "        'insect', 'bug', 'poisoning', 'sick', 'stomach', 'diarrhea', 'vomit',\n",
    "        'hair', 'worm'\n",
    "    ],\n",
    "\n",
    "    'HALAL COMPLIANCE': [\n",
    "        'halal', 'muslim', 'syariah', 'zabihah', 'prayer', 'surau', 'solat',\n",
    "        'mosque', 'wudhu', 'muslimah', 'jakim', 'bersih', 'suci', 'JAKIM',\n",
    "        'muslim-friendly', 'pork-free'\n",
    "    ],\n",
    "\n",
    "    'NON-HALAL ELEMENTS': [\n",
    "        'pork', 'lard', 'babi', 'alcohol', 'beer', 'wine', 'liquor', 'stout',\n",
    "        'draught', 'pint', 'cocktail', 'pub', 'bar', 'char siew', 'siew yoke', 'pour'\n",
    "    ],\n",
    "\n",
    "    'AUTHENTICITY & LOCAL VIBE':[\n",
    "        'authentic', 'traditional', 'asli', 'original', 'local', 'typical',\n",
    "        'kampung', 'fusion', 'modern', 'style', 'muhibbah', 'mamak', 'nyonya',\n",
    "        'penang', 'ipoh', 'heritage', 'classic'\n",
    "    ],\n",
    "\n",
    "    'LOYALTY (RETURN INTENT)': [\n",
    "        'come', 'coming', 'return', 'visit', 'repeat', 'recommend', 'suggestion', 'recommended'\n",
    "        'choice', 'option', 'second', 'again', 'definitely','unacceptable',\n",
    "        'sure', 'always', 'regular', 'back', 'must try', 'disappointed', 'favourite', 'repeatable'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Flatten dictionary for faster lookup\n",
    "KEYWORD_TO_ASPECT = {word: aspect for aspect, keywords in ASPECT_DICT.items() for word in keywords}\n",
    "\n",
    "# Get a clean list of unique keywords\n",
    "unique_keywords = [k for k in KEYWORD_TO_ASPECT.keys() if len(k) > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6ee4708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_aspects_fuzzy(segment):\n",
    "    \"\"\"\n",
    "    Maps a text segment to aspects using Exact Match AND Fuzzy Match.\n",
    "    Includes 'Emoji Protection' to stop warnings.\n",
    "    \"\"\"\n",
    "    found_aspects = set()\n",
    "    words = segment.split()\n",
    "\n",
    "    for word in words:\n",
    "        # CLEANUP: Remove punctuation\n",
    "        clean_word = word.strip(\".,!?\").lower()\n",
    "\n",
    "        if len(clean_word) < 3:\n",
    "            continue\n",
    "\n",
    "        # Skip emoji\n",
    "        # If the word has no letters (a-z), it is likely an emoji or number. Skip it.\n",
    "        if not re.search('[a-zA-Z]', clean_word):\n",
    "            continue\n",
    "\n",
    "        # --- PASS 1: EXACT MATCH  ---\n",
    "        if clean_word in KEYWORD_TO_ASPECT:\n",
    "            found_aspects.add(KEYWORD_TO_ASPECT[clean_word])\n",
    "            continue\n",
    "\n",
    "        # --- PASS 2: FUZZY MATCH  ---\n",
    "        if len(clean_word) > 4:\n",
    "            match, score = process.extractOne(clean_word, unique_keywords)\n",
    "\n",
    "            if score >= 85:\n",
    "                found_aspects.add(KEYWORD_TO_ASPECT[match])\n",
    "\n",
    "    if not found_aspects:\n",
    "        return ['GENERAL']\n",
    "\n",
    "    return list(found_aspects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dba641cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ASPECT DICTIONARY EVALUATION ON GOLD STANDARD\n",
      "============================================================\n",
      "\n",
      "[1/4] Running Aspect Extraction with Fuzzy Matching...\n",
      "✓ Processed 799 segments\n",
      "\n",
      "[2/4] Calculating Multilabel Classification Metrics...\n",
      "✓ Found 9 unique aspects: ['AMBIENCE', 'AUTHENTICITY & LOCAL VIBE', 'FOOD', 'HALAL COMPLIANCE', 'LOCATION', 'LOYALTY (RETURN INTENT)', 'NON-HALAL ELEMENTS', 'SERVICE', 'VALUE']\n",
      "\n",
      "[3/4] Per-Aspect Performance:\n",
      "------------------------------------------------------------\n",
      "AMBIENCE                       | P: 0.802 | R: 0.904 | F1: 0.850 | Support: 94\n",
      "AUTHENTICITY & LOCAL VIBE      | P: 0.769 | R: 0.833 | F1: 0.800 | Support: 24\n",
      "FOOD                           | P: 0.859 | R: 0.955 | F1: 0.904 | Support: 375\n",
      "HALAL COMPLIANCE               | P: 1.000 | R: 1.000 | F1: 1.000 | Support: 2\n",
      "LOCATION                       | P: 0.475 | R: 0.864 | F1: 0.613 | Support: 22\n",
      "LOYALTY (RETURN INTENT)        | P: 0.727 | R: 0.903 | F1: 0.805 | Support: 103\n",
      "NON-HALAL ELEMENTS             | P: 0.909 | R: 0.952 | F1: 0.930 | Support: 21\n",
      "SERVICE                        | P: 0.832 | R: 0.882 | F1: 0.856 | Support: 152\n",
      "VALUE                          | P: 0.829 | R: 0.971 | F1: 0.895 | Support: 105\n",
      "\n",
      "[4/4] Overall Performance Metrics:\n",
      "------------------------------------------------------------\n",
      "Micro-Avg Precision: 0.8127\n",
      "Micro-Avg Recall:    0.9276\n",
      "Micro-Avg F1-Score:  0.8664\n",
      "\n",
      "Macro-Avg Precision: 0.8002\n",
      "Macro-Avg Recall:    0.9182\n",
      "Macro-Avg F1-Score:  0.8504\n",
      "\n",
      "Exact Match Accuracy: 0.7559 (604/799 segments)\n",
      "\n",
      "============================================================\n",
      "EVALUATION COMPLETE ✓\n",
      "============================================================\n",
      "\n",
      "Results stored in: df_results\n",
      "Binary labels stored in: y_true_binary, y_pred_binary\n",
      "Raw predictions stored in: predictions, true_labels\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Evaluates the Aspect Dictionary's performance on the Gold Standard Dataset.\n",
    "This follows a Fuzzy Matching + Exact Matching pipeline and calculates:\n",
    "- Precision: How many predicted aspects were correct?\n",
    "- Recall: How many true aspects were captured?\n",
    "- F1-Score: Harmonic mean of Precision and Recall\n",
    "- Accuracy: Exact match accuracy (per segment)\n",
    "\"\"\"\n",
    "\n",
    "import ast\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ASPECT DICTIONARY EVALUATION ON GOLD STANDARD\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ==========================================\n",
    "# STEP 1: PREDICT ASPECTS FOR EACH SEGMENT\n",
    "# ==========================================\n",
    "print(\"\\n[1/4] Running Aspect Extraction with Fuzzy Matching...\")\n",
    "\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "for index, row in df_gold.iterrows():\n",
    "    segment_text = row['Segment']\n",
    "    \n",
    "    # Parse the Manual_Aspect column (it's stored as a string representation of a list)\n",
    "    try:\n",
    "        true_aspects = ast.literal_eval(row['Manual_Aspect'])\n",
    "        if not isinstance(true_aspects, list):\n",
    "            true_aspects = [true_aspects]\n",
    "    except:\n",
    "        true_aspects = []\n",
    "    \n",
    "    # Predict aspects using our fuzzy matching function\n",
    "    predicted_aspects = identify_aspects_fuzzy(segment_text)\n",
    "    \n",
    "    # Remove 'GENERAL' from predictions for fair comparison\n",
    "    predicted_aspects = [a for a in predicted_aspects if a != 'GENERAL']\n",
    "    \n",
    "    predictions.append(predicted_aspects)\n",
    "    true_labels.append(true_aspects)\n",
    "\n",
    "print(f\"✓ Processed {len(df_gold)} segments\")\n",
    "\n",
    "# ==========================================\n",
    "# STEP 2: CALCULATE MULTILABEL METRICS\n",
    "# ==========================================\n",
    "print(\"\\n[2/4] Calculating Multilabel Classification Metrics...\")\n",
    "\n",
    "# Get all unique aspects from both predictions and true labels\n",
    "all_aspects = sorted(list(set(\n",
    "    [aspect for pred in predictions for aspect in pred] +\n",
    "    [aspect for true in true_labels for aspect in true]\n",
    ")))\n",
    "\n",
    "print(f\"✓ Found {len(all_aspects)} unique aspects: {all_aspects}\")\n",
    "\n",
    "# Convert to binary multilabel format\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=all_aspects)\n",
    "y_true_binary = mlb.fit_transform(true_labels)\n",
    "y_pred_binary = mlb.transform(predictions)\n",
    "\n",
    "# Calculate metrics per aspect\n",
    "print(\"\\n[3/4] Per-Aspect Performance:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "aspect_metrics = []\n",
    "for i, aspect in enumerate(all_aspects):\n",
    "    y_true_aspect = y_true_binary[:, i]\n",
    "    y_pred_aspect = y_pred_binary[:, i]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    tp = np.sum((y_true_aspect == 1) & (y_pred_aspect == 1))\n",
    "    fp = np.sum((y_true_aspect == 0) & (y_pred_aspect == 1))\n",
    "    fn = np.sum((y_true_aspect == 1) & (y_pred_aspect == 0))\n",
    "    tn = np.sum((y_true_aspect == 0) & (y_pred_aspect == 0))\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    support = np.sum(y_true_aspect)\n",
    "    \n",
    "    aspect_metrics.append({\n",
    "        'Aspect': aspect,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'Support': support\n",
    "    })\n",
    "    \n",
    "    print(f\"{aspect:30s} | P: {precision:.3f} | R: {recall:.3f} | F1: {f1:.3f} | Support: {support}\")\n",
    "\n",
    "# ==========================================\n",
    "# STEP 3: CALCULATE OVERALL METRICS\n",
    "# ==========================================\n",
    "print(\"\\n[4/4] Overall Performance Metrics:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Micro-averaged metrics (treats each label equally)\n",
    "tp_total = np.sum((y_true_binary == 1) & (y_pred_binary == 1))\n",
    "fp_total = np.sum((y_true_binary == 0) & (y_pred_binary == 1))\n",
    "fn_total = np.sum((y_true_binary == 1) & (y_pred_binary == 0))\n",
    "\n",
    "micro_precision = tp_total / (tp_total + fp_total) if (tp_total + fp_total) > 0 else 0\n",
    "micro_recall = tp_total / (tp_total + fn_total) if (tp_total + fn_total) > 0 else 0\n",
    "micro_f1 = 2 * (micro_precision * micro_recall) / (micro_precision + micro_recall) if (micro_precision + micro_recall) > 0 else 0\n",
    "\n",
    "print(f\"Micro-Avg Precision: {micro_precision:.4f}\")\n",
    "print(f\"Micro-Avg Recall:    {micro_recall:.4f}\")\n",
    "print(f\"Micro-Avg F1-Score:  {micro_f1:.4f}\")\n",
    "\n",
    "# Macro-averaged metrics (average across aspects)\n",
    "macro_precision = np.mean([m['Precision'] for m in aspect_metrics])\n",
    "macro_recall = np.mean([m['Recall'] for m in aspect_metrics])\n",
    "macro_f1 = np.mean([m['F1-Score'] for m in aspect_metrics])\n",
    "\n",
    "print(f\"\\nMacro-Avg Precision: {macro_precision:.4f}\")\n",
    "print(f\"Macro-Avg Recall:    {macro_recall:.4f}\")\n",
    "print(f\"Macro-Avg F1-Score:  {macro_f1:.4f}\")\n",
    "\n",
    "# Exact match accuracy (how many segments had all aspects correctly predicted)\n",
    "exact_matches = sum([set(pred) == set(true) for pred, true in zip(predictions, true_labels)])\n",
    "exact_match_accuracy = exact_matches / len(predictions)\n",
    "\n",
    "print(f\"\\nExact Match Accuracy: {exact_match_accuracy:.4f} ({exact_matches}/{len(predictions)} segments)\")\n",
    "\n",
    "# ==========================================\n",
    "# STEP 4: CREATE RESULTS DATAFRAME\n",
    "# ==========================================\n",
    "df_results = pd.DataFrame(aspect_metrics)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EVALUATION COMPLETE ✓\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nResults stored in: df_results\")\n",
    "print(f\"Binary labels stored in: y_true_binary, y_pred_binary\")\n",
    "print(f\"Raw predictions stored in: predictions, true_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7579f241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MISMATCH ANALYSIS: Finding Dictionary Weaknesses\n",
      "============================================================\n",
      "\n",
      "✓ Found 195 mismatched segments out of 799 total\n",
      "  → Match Rate: 75.59%\n",
      "\n",
      "------------------------------------------------------------\n",
      "MISMATCH BREAKDOWN:\n",
      "------------------------------------------------------------\n",
      "\n",
      "By Type:\n",
      "  Extra     :  131 segments (67.2%)\n",
      "  Both      :   38 segments (19.5%)\n",
      "  Missing   :   26 segments (13.3%)\n",
      "\n",
      "Most Commonly MISSED Aspects (False Negatives):\n",
      "  SERVICE                       :   18 times\n",
      "  FOOD                          :   17 times\n",
      "  LOYALTY (RETURN INTENT)       :   10 times\n",
      "  AMBIENCE                      :    9 times\n",
      "  AUTHENTICITY & LOCAL VIBE     :    4 times\n",
      "\n",
      "Most Commonly OVER-PREDICTED Aspects (False Positives):\n",
      "  FOOD                          :   59 times\n",
      "  LOYALTY (RETURN INTENT)       :   35 times\n",
      "  SERVICE                       :   27 times\n",
      "  LOCATION                      :   21 times\n",
      "  VALUE                         :   21 times\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Filter and analyze segments where predicted aspects differ from manual annotations.\n",
    "This helps identify weaknesses in the aspect dictionary.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MISMATCH ANALYSIS: Finding Dictionary Weaknesses\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ==========================================\n",
    "# CREATE DETAILED COMPARISON DATAFRAME\n",
    "# ==========================================\n",
    "mismatches = []\n",
    "\n",
    "for i, (pred, true) in enumerate(zip(predictions, true_labels)):\n",
    "    pred_set = set(pred)\n",
    "    true_set = set(true)\n",
    "    \n",
    "    # Check if there's any difference\n",
    "    if pred_set != true_set:\n",
    "        segment_text = df_gold.iloc[i]['Segment']\n",
    "        \n",
    "        # Calculate what's missing and what's extra\n",
    "        missing_aspects = true_set - pred_set  # Should have predicted but didn't\n",
    "        extra_aspects = pred_set - true_set    # Predicted but shouldn't have\n",
    "        \n",
    "        mismatches.append({\n",
    "            'Segment_ID': i,\n",
    "            'Segment_Text': segment_text,\n",
    "            'Manual_Aspects': sorted(list(true_set)),\n",
    "            'Predicted_Aspects': sorted(list(pred_set)),\n",
    "            'Missing_Aspects': sorted(list(missing_aspects)),\n",
    "            'Extra_Aspects': sorted(list(extra_aspects)),\n",
    "            'Mismatch_Type': 'Both' if (missing_aspects and extra_aspects) else ('Missing' if missing_aspects else 'Extra')\n",
    "        })\n",
    "\n",
    "df_mismatches = pd.DataFrame(mismatches)\n",
    "\n",
    "print(f\"\\n✓ Found {len(df_mismatches)} mismatched segments out of {len(df_gold)} total\")\n",
    "print(f\"  → Match Rate: {(1 - len(df_mismatches)/len(df_gold))*100:.2f}%\")\n",
    "\n",
    "# ==========================================\n",
    "# SUMMARY STATISTICS\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"MISMATCH BREAKDOWN:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Count by mismatch type\n",
    "mismatch_counts = df_mismatches['Mismatch_Type'].value_counts()\n",
    "print(\"\\nBy Type:\")\n",
    "for mtype, count in mismatch_counts.items():\n",
    "    print(f\"  {mtype:10s}: {count:4d} segments ({count/len(df_mismatches)*100:.1f}%)\")\n",
    "\n",
    "# Most commonly missed aspects\n",
    "all_missing = [asp for row in df_mismatches['Missing_Aspects'] for asp in row if asp]\n",
    "if all_missing:\n",
    "    print(\"\\nMost Commonly MISSED Aspects (False Negatives):\")\n",
    "    missing_counts = pd.Series(all_missing).value_counts()\n",
    "    for aspect, count in missing_counts.head(5).items():\n",
    "        print(f\"  {aspect:30s}: {count:4d} times\")\n",
    "\n",
    "# Most commonly over-predicted aspects\n",
    "all_extra = [asp for row in df_mismatches['Extra_Aspects'] for asp in row if asp]\n",
    "if all_extra:\n",
    "    print(\"\\nMost Commonly OVER-PREDICTED Aspects (False Positives):\")\n",
    "    extra_counts = pd.Series(all_extra).value_counts()\n",
    "    for aspect, count in extra_counts.head(5).items():\n",
    "        print(f\"  {aspect:30s}: {count:4d} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66d9ddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dataframe for interactive exploration\n",
    "df_mismatches.to_csv(r'C:\\Users\\Ong Hui Ling\\Dropbox\\PC\\Documents\\Github\\Aspect-Based-Sentiment-Analysis\\Dataset\\Mismatched_Aspect_Gold_Standard.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
